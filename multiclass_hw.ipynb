{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTlmjXExP75I"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 4. Классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH11bAAV2SoV"
      },
      "source": [
        "### Общая информация\n",
        "Дата выдачи: 16.11.2024\n",
        "\n",
        "Мягкий дедлайн: 28.11.2024\n",
        "\n",
        "Жесткий дедлайн: 02.12.2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import polars as pl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "# pl.Config().set_tbl_rows(100)\n",
        "# pl.Config().set_tbl_cols(100)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.13.3)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (2.0.34)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eELf9JBWM9D5"
      },
      "source": [
        "# __Бонусная часть. Многоклассовая классификация__ (1.5 балла)\n",
        "\n",
        "Как известно, некоторые задачи не ограничиваются всего лишь двумя классами. На лекции вы проходили несколько способов обобщения линейных моделей на этот случай: One-vs-Rest и One-vs-One. Ниже мы посмотрим, в чём преимущества и недостатки обоих подходов, а так же попробуем ещё один чуть более экзотический метод\n",
        "\n",
        "#### **Задание 14. One-vs-Rest vs One-vs-One** (0.5 балла)\n",
        "\n",
        "В качестве [датасета](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention/data) здесь и ниже мы будем брать очень жизненные и актуальные данные о том, доучится студент или нет, в зависимости от курсов, возраста, гендера и прочих (не)осуждаемых признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "23xX_I3bO3uQ"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"thedevastator/higher-education-predictors-of-student-retention\") + \"/dataset.csv\"\n",
        "\n",
        "features = [\"Marital status\", \"Course\", \"Nacionality\", \"Gender\", \"Age at enrollment\"]\n",
        "target = \"Target\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMuDGcDiO6bI"
      },
      "source": [
        "Будем смотреть только какое-то подмножество наиболее весёлых факторов. От вас по классике потребуется их преобразовать, в зависимости от того, числовые они или категориальные и **закодировать таргет чиселками!!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_Y8NbWwPPVHZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:\\\\Users\\\\User\\\\.cache\\\\kagglehub\\\\datasets\\\\thedevastator\\\\higher-education-predictors-of-student-retention\\\\versions\\\\2/dataset.csv'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df[features]\n",
        "y = df[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Изучаю признаки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Marital status', 'Course', 'Nacionality', 'Gender',\n",
              "       'Age at enrollment'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Course</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age at enrollment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Marital status  Course  Nacionality  Gender  Age at enrollment\n",
              "0               1       2            1       1                 20\n",
              "1               1      11            1       1                 19\n",
              "2               1       5            1       1                 19\n",
              "3               1      15            1       0                 20\n",
              "4               2       3            1       0                 45"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Marital status\n",
              "1    3919\n",
              "2     379\n",
              "4      91\n",
              "5      25\n",
              "6       6\n",
              "3       4\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['Marital status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Этот признак будем считать категориальным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    4424.000000\n",
              "mean        9.899186\n",
              "std         4.331792\n",
              "min         1.000000\n",
              "25%         6.000000\n",
              "50%        10.000000\n",
              "75%        13.000000\n",
              "max        17.000000\n",
              "Name: Course, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['Course'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Текущий курс студента. Тоже будем считать категориальным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    4424.000000\n",
              "mean        1.254521\n",
              "std         1.748447\n",
              "min         1.000000\n",
              "25%         1.000000\n",
              "50%         1.000000\n",
              "75%         1.000000\n",
              "max        21.000000\n",
              "Name: Nacionality, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['Nacionality'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Национальность тоже категориальный признак"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    4424.000000\n",
              "mean        0.351718\n",
              "std         0.477560\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%         1.000000\n",
              "max         1.000000\n",
              "Name: Gender, dtype: float64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['Gender'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Пол, естественно, считаем категориальным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    4424.000000\n",
              "mean       23.265145\n",
              "std         7.587816\n",
              "min        17.000000\n",
              "25%        19.000000\n",
              "50%        20.000000\n",
              "75%        25.000000\n",
              "max        70.000000\n",
              "Name: Age at enrollment, dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['Age at enrollment'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Возраст при поступлении логично отнести к числовым признакам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Dropout', 'Graduate', 'Enrolled'], dtype=object)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Target\n",
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Enrolled** - учится на момент сбора данных\\\n",
        "**Dropout** - отчислен\\\n",
        "**Graduate** - успешно выпустился    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подготовка признаков к моделированию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_features = [\"Marital status\", \"Course\", \"Nacionality\", \"Gender\"]  # категориальные признаки\n",
        "numeric_features = [\"Age at enrollment\"] # числовые признаки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.where(y == 'Dropout', 0,\n",
        "    np.where(y == 'Enrolled', 1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=228, shuffle=True, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessor1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "preprocessor1.fit(X_train)\n",
        "X_train_transformed = preprocessor1.transform(X_train)\n",
        "X_test_transformed = preprocessor1.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4cGqq_kPfrQ"
      },
      "source": [
        "Ваш следующий шаг - посмотреть, каким образом в `sklearn` реализованы OvR и OvO, обучить таким образом логистическую регрессию с `max_iter=10000`, далее выбрать какую-то метрику (и её усреднение, его выбор тоже аргументируйте), и сравнить следующие параметры:\n",
        "- число классификаторов\n",
        "- скорость обучения\n",
        "- качество модели\n",
        "\n",
        "Также сохраните куда-нибудь предсказания вероятностей у каждой из моделей. Это можно сделать не одним способом, но возможно вам чуть с этим поможет следующий пункт\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**One vs Rest**: для каждого класса создается отдельный бинарный классификатор. Считается менее точным. Обучается быстрее, так как для K классов нужно K классификаторов\\\n",
        "\n",
        "**One vs one**: для каждой пары классов создается отдельный бинарный классификатор. Каждый классификатор обучается отличать одну пару классов. На предсказании используется голосование. Часто более высокая точность. Медленнее, так как требует обучения K^2 моделей.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# табличка для сравнения\n",
        "\n",
        "df_metrics = pd.DataFrame(\n",
        "    columns=['macro_F1', 'macro_precision', 'macro_recall', 'Количество классификаторов', 'Скорость обучения (секунд)']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение OvR модели заняло 0.077 секунд\n",
            "Количество классификаторов = 3\n"
          ]
        }
      ],
      "source": [
        "start_ovr = time.time()\n",
        "\n",
        "ovr_model = OneVsRestClassifier(LogisticRegression(penalty='l2',\n",
        "        #C=1.0,                                                           # для начала обучу дефолтную модель с l2 регуляризацией\n",
        "        max_iter=1000))\n",
        "ovr_model = ovr_model.fit(X_train_transformed, y_train)\n",
        "time_ovr = time.time() - start_ovr\n",
        "print(f'Обучение OvR модели заняло {round(time_ovr, 3)} секунд')\n",
        "print(f\"Количество классификаторов = {len(ovr_model.estimators_)}\")\n",
        "y_pred_ovr = ovr_model.predict(X_test_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я считаю, что в данном случае лучшим выбором будет **Macro F1-score**, так как есть дисбаланс классов. С помощью этой метрики мы сможем понять, насколько хорошо модель предсказывает все классы.\\\n",
        "Также я оценю **macro precision и macro recall**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "precision_per_class_ovr = precision_score(y_test, y_pred_ovr, average=None)\n",
        "recall_per_class_ovr = recall_score(y_test, y_pred_ovr, average=None)\n",
        "f1_per_class_ovr = f1_score(y_test, y_pred_ovr, average=None)\n",
        "\n",
        "df_metrics.loc['One-vs-Rest with Logistic Regression'] = [\n",
        "      f1_per_class_ovr.mean(),\n",
        "      precision_per_class_ovr.mean(),\n",
        "      recall_per_class_ovr.mean(),\n",
        "      len(ovr_model.estimators_),\n",
        "      round(time_ovr, 3)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>macro_F1</th>\n",
              "      <th>macro_precision</th>\n",
              "      <th>macro_recall</th>\n",
              "      <th>Количество классификаторов</th>\n",
              "      <th>Скорость обучения (секунд)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>One-vs-Rest with Logistic Regression</th>\n",
              "      <td>0.397389</td>\n",
              "      <td>0.532561</td>\n",
              "      <td>0.434916</td>\n",
              "      <td>3</td>\n",
              "      <td>0.077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      macro_F1 macro_precision macro_recall  \\\n",
              "One-vs-Rest with Logistic Regression  0.397389        0.532561     0.434916   \n",
              "\n",
              "                                      Количество классификаторов  \\\n",
              "One-vs-Rest with Logistic Regression                           3   \n",
              "\n",
              "                                      Скорость обучения (секунд)  \n",
              "One-vs-Rest with Logistic Regression                       0.077  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "для дефолтной лог регрессии качество не очень"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение OvO модели заняло 0.064 секунд\n",
            "Количество классификаторов = 3\n"
          ]
        }
      ],
      "source": [
        "# обучим One-vs-One\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "start_ovo = time.time()\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(penalty='l2',\n",
        "        #C=1.0,                                                           # для начала обучу дефолтную модель с l2 регуляризацией\n",
        "        max_iter=1000))\n",
        "ovo_model = ovo_model.fit(X_train_transformed, y_train)\n",
        "time_ovo = time.time() - start_ovo\n",
        "print(f'Обучение OvO модели заняло {round(time_ovo, 3)} секунд')\n",
        "print(f\"Количество классификаторов = {len(ovo_model.estimators_)}\")\n",
        "y_pred_ovo = ovo_model.predict(X_test_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision_per_class_ovo = precision_score(y_test, y_pred_ovo, average=None)\n",
        "recall_per_class_ovo = recall_score(y_test, y_pred_ovo, average=None)\n",
        "f1_per_class_ovo = f1_score(y_test, y_pred_ovo, average=None)\n",
        "\n",
        "df_metrics.loc['One-vs-One with Logistic Regression'] = [\n",
        "      f1_per_class_ovo.mean(),\n",
        "      precision_per_class_ovo.mean(),\n",
        "      recall_per_class_ovo.mean(),\n",
        "      len(ovo_model.estimators_),\n",
        "      round(time_ovo, 3)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_255fb_row0_col0, #T_255fb_row0_col1, #T_255fb_row0_col2, #T_255fb_row0_col4 {\n",
              "  background-color: #a50026;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_255fb_row1_col0, #T_255fb_row1_col1, #T_255fb_row1_col2, #T_255fb_row1_col4 {\n",
              "  background-color: #006837;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_255fb\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_255fb_level0_col0\" class=\"col_heading level0 col0\" >macro_F1</th>\n",
              "      <th id=\"T_255fb_level0_col1\" class=\"col_heading level0 col1\" >macro_precision</th>\n",
              "      <th id=\"T_255fb_level0_col2\" class=\"col_heading level0 col2\" >macro_recall</th>\n",
              "      <th id=\"T_255fb_level0_col3\" class=\"col_heading level0 col3\" >Количество классификаторов</th>\n",
              "      <th id=\"T_255fb_level0_col4\" class=\"col_heading level0 col4\" >Скорость обучения (секунд)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_255fb_level0_row0\" class=\"row_heading level0 row0\" >One-vs-Rest with Logistic Regression</th>\n",
              "      <td id=\"T_255fb_row0_col0\" class=\"data row0 col0\" >0.397389</td>\n",
              "      <td id=\"T_255fb_row0_col1\" class=\"data row0 col1\" >0.532561</td>\n",
              "      <td id=\"T_255fb_row0_col2\" class=\"data row0 col2\" >0.434916</td>\n",
              "      <td id=\"T_255fb_row0_col3\" class=\"data row0 col3\" >3.000000</td>\n",
              "      <td id=\"T_255fb_row0_col4\" class=\"data row0 col4\" >0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_255fb_level0_row1\" class=\"row_heading level0 row1\" >One-vs-One with Logistic Regression</th>\n",
              "      <td id=\"T_255fb_row1_col0\" class=\"data row1 col0\" >0.413611</td>\n",
              "      <td id=\"T_255fb_row1_col1\" class=\"data row1 col1\" >0.535071</td>\n",
              "      <td id=\"T_255fb_row1_col2\" class=\"data row1 col2\" >0.441842</td>\n",
              "      <td id=\"T_255fb_row1_col3\" class=\"data row1 col3\" >3.000000</td>\n",
              "      <td id=\"T_255fb_row1_col4\" class=\"data row1 col4\" >0.064000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1d4191cc410>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df_metrics.style\n",
        "    .background_gradient(subset=['macro_F1', 'macro_precision', 'macro_recall'], cmap='RdYlGn')\n",
        "    .background_gradient(subset=['Скорость обучения (секунд)'], cmap='RdYlGn_r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как и ожидалось, качество чуть лучше у One-vs-One. При этом качество обеих моделей оставляет желать лучшего, поэтому я попробую подобрать **оптимальные гиперпараметры**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-12 16:06:18,675] A new study created in memory with name: no-name-7c2e2c0c-89ea-4d11-8a7f-8fe880835eed\n",
            "[I 2025-10-12 16:06:18,788] Trial 0 finished with value: 0.41281828611197824 and parameters: {'C': 49.95361048685655, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.41281828611197824.\n",
            "[I 2025-10-12 16:06:18,829] Trial 1 finished with value: 0.4128961456771485 and parameters: {'C': 4.818080052572582, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:18,931] Trial 2 finished with value: 0.41281828611197824 and parameters: {'C': 37.9992085291004, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:18,951] Trial 3 finished with value: 0.4007669502011022 and parameters: {'C': 0.2085323889092576, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:18,990] Trial 4 finished with value: 0.41281828611197824 and parameters: {'C': 263.9794337912012, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,067] Trial 5 finished with value: 0.41281828611197824 and parameters: {'C': 16.20073321034819, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,172] Trial 6 finished with value: 0.41281828611197824 and parameters: {'C': 163.47056322026222, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,211] Trial 7 finished with value: 0.4128961456771485 and parameters: {'C': 3.6995535507549233, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,313] Trial 8 finished with value: 0.41281828611197824 and parameters: {'C': 37.27622846399435, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,410] Trial 9 finished with value: 0.41281828611197824 and parameters: {'C': 135.52446253484734, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,439] Trial 10 finished with value: 0.3001410559601752 and parameters: {'C': 0.001258269799106754, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,492] Trial 11 finished with value: 0.39769992455904085 and parameters: {'C': 0.7836660724316536, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,575] Trial 12 finished with value: 0.4128961456771485 and parameters: {'C': 3.659467119316725, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,613] Trial 13 finished with value: 0.39773000306717304 and parameters: {'C': 0.0801375941306271, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,667] Trial 14 finished with value: 0.4128961456771485 and parameters: {'C': 3.6922865759059404, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,687] Trial 15 finished with value: 0.36317054316962477 and parameters: {'C': 0.028415644092043096, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,728] Trial 16 finished with value: 0.4128961456771485 and parameters: {'C': 3.574730821061748, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,763] Trial 17 finished with value: 0.39905574213878436 and parameters: {'C': 0.5800423084662909, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,799] Trial 18 finished with value: 0.361764255068118 and parameters: {'C': 0.006758898314408856, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,815] Trial 19 finished with value: 0.41281828611197824 and parameters: {'C': 857.0449938598414, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,872] Trial 20 finished with value: 0.41281828611197824 and parameters: {'C': 9.22703159319506, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,909] Trial 21 finished with value: 0.4128961456771485 and parameters: {'C': 3.1487262473427813, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,941] Trial 22 finished with value: 0.4128961456771485 and parameters: {'C': 1.7487513216020147, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:19,982] Trial 23 finished with value: 0.39905574213878436 and parameters: {'C': 0.5592784228368158, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,047] Trial 24 finished with value: 0.41281828611197824 and parameters: {'C': 11.159727587587769, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,069] Trial 25 finished with value: 0.4033579837414331 and parameters: {'C': 0.12134104147804495, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,149] Trial 26 finished with value: 0.41281828611197824 and parameters: {'C': 5.896327693828239, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,181] Trial 27 finished with value: 0.4128961456771485 and parameters: {'C': 1.6035448265608199, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,211] Trial 28 finished with value: 0.39997074018255035 and parameters: {'C': 0.2933938079038988, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,294] Trial 29 finished with value: 0.41281828611197824 and parameters: {'C': 44.125114236691516, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,380] Trial 30 finished with value: 0.41281828611197824 and parameters: {'C': 18.56427818626443, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,420] Trial 31 finished with value: 0.4128961456771485 and parameters: {'C': 3.777096667481801, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,449] Trial 32 finished with value: 0.4128961456771485 and parameters: {'C': 1.6929604105684244, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,550] Trial 33 finished with value: 0.41281828611197824 and parameters: {'C': 25.0310381104299, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,664] Trial 34 finished with value: 0.41281828611197824 and parameters: {'C': 84.81555142337035, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,714] Trial 35 finished with value: 0.41281828611197824 and parameters: {'C': 6.0543911010358205, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,763] Trial 36 finished with value: 0.40087566644725353 and parameters: {'C': 0.3020781335330779, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 1 with value: 0.4128961456771485.\n",
            "[I 2025-10-12 16:06:20,799] Trial 37 finished with value: 0.4136110155202804 and parameters: {'C': 1.150228736410445, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:20,842] Trial 38 finished with value: 0.3951693166646438 and parameters: {'C': 0.05776222871309327, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:20,872] Trial 39 finished with value: 0.4136110155202804 and parameters: {'C': 0.9629431348223622, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:20,906] Trial 40 finished with value: 0.4136110155202804 and parameters: {'C': 1.0140475285268367, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:20,941] Trial 41 finished with value: 0.4136110155202804 and parameters: {'C': 1.0380867915052365, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:20,998] Trial 42 finished with value: 0.4128961456771485 and parameters: {'C': 1.4567389291981525, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,039] Trial 43 finished with value: 0.398903866718659 and parameters: {'C': 0.5189909303728383, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,064] Trial 44 finished with value: 0.4028872513828081 and parameters: {'C': 0.1895351390239439, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,097] Trial 45 finished with value: 0.40024198175918774 and parameters: {'C': 0.9234293584192268, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,128] Trial 46 finished with value: 0.3991338788231131 and parameters: {'C': 0.388824517953351, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,188] Trial 47 finished with value: 0.4136110155202804 and parameters: {'C': 0.9517424147725613, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,229] Trial 48 finished with value: 0.40684924583384513 and parameters: {'C': 0.11246525112734884, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n",
            "[I 2025-10-12 16:06:21,270] Trial 49 finished with value: 0.40079269548191077 and parameters: {'C': 0.18503065234460314, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 37 with value: 0.4136110155202804.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшие параметры: {'C': 1.150228736410445, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Лучший macro F1-score: 0.4136110155202804\n",
            "Общее время Optuna: 2.596 секунд\n"
          ]
        }
      ],
      "source": [
        "# для One-vs-One\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
        "    \n",
        "    if penalty == 'l1':\n",
        "        solver = 'liblinear'\n",
        "    elif penalty == 'l2':\n",
        "        solver = 'lbfgs'  \n",
        "    \n",
        "    base_estimator = LogisticRegression(\n",
        "        C=C,\n",
        "        penalty=penalty,\n",
        "        solver=solver,\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    model = OneVsOneClassifier(base_estimator)\n",
        "    model.fit(X_train_transformed, y_train)\n",
        "    \n",
        "    trial.set_user_attr('model', model)\n",
        "    \n",
        "    y_pred = model.predict(X_test_transformed)\n",
        "    score = f1_score(y_test, y_pred, average='macro')\n",
        "    return score\n",
        "\n",
        "start_optuna = time.time()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "time_optuna_total = time.time() - start_optuna\n",
        "\n",
        "print(\"Лучшие параметры:\", study.best_params)\n",
        "print(\"Лучший macro F1-score:\", study.best_value)\n",
        "print(f\"Общее время Optuna: {round(time_optuna_total, 3)} секунд\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Не удалось значимо увеличить macro F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_trial = study.best_trial                                 # извлекаю лучшую модель\n",
        "best_ovo_model = best_trial.user_attrs['model']\n",
        "\n",
        "y_pred_ovo_optuna = best_ovo_model.predict(X_test_transformed)\n",
        "\n",
        "precision_per_class_ovo_optuna = precision_score(y_test, y_pred_ovo_optuna, average=None)\n",
        "recall_per_class_ovo_optuna = recall_score(y_test, y_pred_ovo_optuna, average=None)\n",
        "f1_per_class_ovo_optuna = f1_score(y_test, y_pred_ovo_optuna, average=None)\n",
        "\n",
        "df_metrics.loc['One-vs-One + Optuna with Logistic Regression'] = [\n",
        "    f1_per_class_ovo_optuna.mean(),\n",
        "    precision_per_class_ovo_optuna.mean(),\n",
        "    recall_per_class_ovo_optuna.mean(),\n",
        "    len(best_ovo_model.estimators_),\n",
        "    round(time_optuna_total, 3)  \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_044d6_row0_col0, #T_044d6_row0_col1, #T_044d6_row0_col2, #T_044d6_row2_col4 {\n",
              "  background-color: #a50026;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_044d6_row0_col4 {\n",
              "  background-color: #016a38;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_044d6_row1_col0, #T_044d6_row1_col1, #T_044d6_row1_col2, #T_044d6_row1_col4, #T_044d6_row2_col0, #T_044d6_row2_col1, #T_044d6_row2_col2 {\n",
              "  background-color: #006837;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_044d6\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_044d6_level0_col0\" class=\"col_heading level0 col0\" >macro_F1</th>\n",
              "      <th id=\"T_044d6_level0_col1\" class=\"col_heading level0 col1\" >macro_precision</th>\n",
              "      <th id=\"T_044d6_level0_col2\" class=\"col_heading level0 col2\" >macro_recall</th>\n",
              "      <th id=\"T_044d6_level0_col3\" class=\"col_heading level0 col3\" >Количество классификаторов</th>\n",
              "      <th id=\"T_044d6_level0_col4\" class=\"col_heading level0 col4\" >Скорость обучения (секунд)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_044d6_level0_row0\" class=\"row_heading level0 row0\" >One-vs-Rest with Logistic Regression</th>\n",
              "      <td id=\"T_044d6_row0_col0\" class=\"data row0 col0\" >0.397389</td>\n",
              "      <td id=\"T_044d6_row0_col1\" class=\"data row0 col1\" >0.532561</td>\n",
              "      <td id=\"T_044d6_row0_col2\" class=\"data row0 col2\" >0.434916</td>\n",
              "      <td id=\"T_044d6_row0_col3\" class=\"data row0 col3\" >3</td>\n",
              "      <td id=\"T_044d6_row0_col4\" class=\"data row0 col4\" >0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_044d6_level0_row1\" class=\"row_heading level0 row1\" >One-vs-One with Logistic Regression</th>\n",
              "      <td id=\"T_044d6_row1_col0\" class=\"data row1 col0\" >0.413611</td>\n",
              "      <td id=\"T_044d6_row1_col1\" class=\"data row1 col1\" >0.535071</td>\n",
              "      <td id=\"T_044d6_row1_col2\" class=\"data row1 col2\" >0.441842</td>\n",
              "      <td id=\"T_044d6_row1_col3\" class=\"data row1 col3\" >3</td>\n",
              "      <td id=\"T_044d6_row1_col4\" class=\"data row1 col4\" >0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_044d6_level0_row2\" class=\"row_heading level0 row2\" >One-vs-One + Optuna with Logistic Regression</th>\n",
              "      <td id=\"T_044d6_row2_col0\" class=\"data row2 col0\" >0.413611</td>\n",
              "      <td id=\"T_044d6_row2_col1\" class=\"data row2 col1\" >0.535071</td>\n",
              "      <td id=\"T_044d6_row2_col2\" class=\"data row2 col2\" >0.441842</td>\n",
              "      <td id=\"T_044d6_row2_col3\" class=\"data row2 col3\" >3</td>\n",
              "      <td id=\"T_044d6_row2_col4\" class=\"data row2 col4\" >2.596000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1d4143708c0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_metrics['Количество классификаторов'] = df_metrics['Количество классификаторов'].astype(int)\n",
        "display(df_metrics.style\n",
        "    .background_gradient(subset=['macro_F1', 'macro_precision', 'macro_recall'], cmap='RdYlGn')\n",
        "    .background_gradient(subset=['Скорость обучения (секунд)'], cmap='RdYlGn_r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "BuO6VHE1P4dA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-12 16:31:45,151] A new study created in memory with name: no-name-8a64c457-3413-4244-adc9-9fa5bfc38f15\n",
            "[I 2025-10-12 16:31:45,211] Trial 0 finished with value: 0.3928721971540921 and parameters: {'C': 0.015162035080912318, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 0 with value: 0.3928721971540921.\n",
            "[I 2025-10-12 16:31:45,243] Trial 1 finished with value: 0.4004648006019833 and parameters: {'C': 0.1304260418785571, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 1 with value: 0.4004648006019833.\n",
            "[I 2025-10-12 16:31:45,272] Trial 2 finished with value: 0.4016074689841929 and parameters: {'C': 0.11244290766609472, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,422] Trial 3 finished with value: 0.39833374176670494 and parameters: {'C': 10.997497965664715, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,547] Trial 4 finished with value: 0.39833374176670494 and parameters: {'C': 6.807847103738868, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,561] Trial 5 finished with value: 0.3197948236365447 and parameters: {'C': 0.0041785882871093905, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,692] Trial 6 finished with value: 0.39833374176670494 and parameters: {'C': 181.70363520008908, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,703] Trial 7 finished with value: 0.22171945701357465 and parameters: {'C': 0.0019638111984826667, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,889] Trial 8 finished with value: 0.39833374176670494 and parameters: {'C': 30.565102614114195, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:45,965] Trial 9 finished with value: 0.39810196653051816 and parameters: {'C': 0.5189286059528554, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 2 with value: 0.4016074689841929.\n",
            "[I 2025-10-12 16:31:46,014] Trial 10 finished with value: 0.40263763645562634 and parameters: {'C': 0.07733343150581139, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,065] Trial 11 finished with value: 0.3990208599404002 and parameters: {'C': 0.07087741645073632, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,139] Trial 12 finished with value: 0.397388694690007 and parameters: {'C': 0.8453403660970459, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,186] Trial 13 finished with value: 0.3952670376116972 and parameters: {'C': 0.04513750176916733, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,219] Trial 14 finished with value: 0.40179109079053354 and parameters: {'C': 0.26933679719758125, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,318] Trial 15 finished with value: 0.397388694690007 and parameters: {'C': 1.7765885667974821, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,352] Trial 16 finished with value: 0.3806603714900658 and parameters: {'C': 0.008191305340101705, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,399] Trial 17 finished with value: 0.397217617485587 and parameters: {'C': 0.47669152440339574, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,554] Trial 18 finished with value: 0.39833374176670494 and parameters: {'C': 799.2162243686087, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,567] Trial 19 finished with value: 0.22171945701357465 and parameters: {'C': 0.0010108802607559629, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,610] Trial 20 finished with value: 0.38921101774042954 and parameters: {'C': 0.028124249667559182, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,639] Trial 21 finished with value: 0.3999714322699995 and parameters: {'C': 0.21133466208513643, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,703] Trial 22 finished with value: 0.3958865433352943 and parameters: {'C': 2.2917134763876623, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.40263763645562634.\n",
            "[I 2025-10-12 16:31:46,731] Trial 23 finished with value: 0.4042084618321735 and parameters: {'C': 0.18442827164379177, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:46,771] Trial 24 finished with value: 0.40179109079053354 and parameters: {'C': 0.2780990978564555, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:46,795] Trial 25 finished with value: 0.38793136850855775 and parameters: {'C': 0.03138584907954715, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:46,867] Trial 26 finished with value: 0.3958865433352943 and parameters: {'C': 3.2801320556310505, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:46,885] Trial 27 finished with value: 0.35994160508833195 and parameters: {'C': 0.010508480659063008, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:46,971] Trial 28 finished with value: 0.397388694690007 and parameters: {'C': 1.1474928369774544, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,010] Trial 29 finished with value: 0.3928721971540921 and parameters: {'C': 0.01583294401590164, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,034] Trial 30 finished with value: 0.39642849964698873 and parameters: {'C': 0.07326124204062268, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,068] Trial 31 finished with value: 0.40179109079053354 and parameters: {'C': 0.30109715661596465, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,101] Trial 32 finished with value: 0.40179109079053354 and parameters: {'C': 0.2553467073436925, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,131] Trial 33 finished with value: 0.40179109079053354 and parameters: {'C': 0.2397372783254999, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,157] Trial 34 finished with value: 0.4004648006019833 and parameters: {'C': 0.13813087359259016, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,229] Trial 35 finished with value: 0.39833374176670494 and parameters: {'C': 5.174956395607859, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,377] Trial 36 finished with value: 0.39833374176670494 and parameters: {'C': 19.10695606993934, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,403] Trial 37 finished with value: 0.40170165898169885 and parameters: {'C': 0.10355161131886871, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,475] Trial 38 finished with value: 0.39723397662070076 and parameters: {'C': 0.7855002977163507, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,495] Trial 39 finished with value: 0.3720729944217966 and parameters: {'C': 0.01830600128484017, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,529] Trial 40 finished with value: 0.35697018638734695 and parameters: {'C': 0.0039201692815386035, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,570] Trial 41 finished with value: 0.39957725256129145 and parameters: {'C': 0.4062917078648661, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,596] Trial 42 finished with value: 0.4004648006019833 and parameters: {'C': 0.13368937183535032, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,619] Trial 43 finished with value: 0.3930205415499533 and parameters: {'C': 0.052576682805809495, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,653] Trial 44 finished with value: 0.40289390804652836 and parameters: {'C': 0.32228044209642037, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,707] Trial 45 finished with value: 0.396522675650816 and parameters: {'C': 1.0744865509013517, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,732] Trial 46 finished with value: 0.4022658073290984 and parameters: {'C': 0.15072541942243228, 'penalty': 'l1', 'solver': 'lbfgs'}. Best is trial 23 with value: 0.4042084618321735.\n",
            "[I 2025-10-12 16:31:47,788] Trial 47 finished with value: 0.4056060063110783 and parameters: {'C': 0.13112505660351512, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 47 with value: 0.4056060063110783.\n",
            "[I 2025-10-12 16:31:47,829] Trial 48 finished with value: 0.39073817014162576 and parameters: {'C': 0.03364383890781203, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 47 with value: 0.4056060063110783.\n",
            "[I 2025-10-12 16:31:47,875] Trial 49 finished with value: 0.40263763645562634 and parameters: {'C': 0.08488094765850861, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 47 with value: 0.4056060063110783.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшие параметры: {'C': 0.13112505660351512, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Лучший macro F1-score: 0.4056060063110783\n",
            "Общее время Optuna: 2.724 секунд\n"
          ]
        }
      ],
      "source": [
        "# теперь One-vs_Rest с Optuna\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
        "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
        "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
        "    \n",
        "    if penalty == 'l1':\n",
        "        solver = 'liblinear'\n",
        "    elif penalty == 'l2':\n",
        "        solver = 'lbfgs'  \n",
        "    \n",
        "    base_estimator = LogisticRegression(\n",
        "        C=C,\n",
        "        penalty=penalty,\n",
        "        solver=solver,\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    model = OneVsRestClassifier(base_estimator)\n",
        "    model.fit(X_train_transformed, y_train)\n",
        "    \n",
        "    trial.set_user_attr('model', model)\n",
        "    \n",
        "    y_pred = model.predict(X_test_transformed)\n",
        "    score = f1_score(y_test, y_pred, average='macro')\n",
        "    return score\n",
        "\n",
        "start_optuna = time.time()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "time_optuna_total = time.time() - start_optuna\n",
        "\n",
        "print(\"Лучшие параметры:\", study.best_params)\n",
        "print(\"Лучший macro F1-score:\", study.best_value)\n",
        "print(f\"Общее время Optuna: {round(time_optuna_total, 3)} секунд\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_trial = study.best_trial                                 # извлекаю лучшую модель\n",
        "best_ovr_model = best_trial.user_attrs['model']\n",
        "\n",
        "y_pred_ovr_optuna = best_ovr_model.predict(X_test_transformed)\n",
        "\n",
        "precision_per_class_ovr_optuna = precision_score(y_test, y_pred_ovr_optuna, average=None)\n",
        "recall_per_class_ovr_optuna = recall_score(y_test, y_pred_ovr_optuna, average=None)\n",
        "f1_per_class_ovr_optuna = f1_score(y_test, y_pred_ovr_optuna, average=None)\n",
        "\n",
        "df_metrics.loc['One-vs-Rest + Optuna with Logistic Regression'] = [\n",
        "    f1_per_class_ovr_optuna.mean(),\n",
        "    precision_per_class_ovr_optuna.mean(),\n",
        "    recall_per_class_ovr_optuna.mean(),\n",
        "    len(best_ovr_model.estimators_),\n",
        "    round(time_optuna_total, 3)  \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_cf17c_row0_col0, #T_cf17c_row0_col1, #T_cf17c_row0_col2, #T_cf17c_row3_col4 {\n",
              "  background-color: #a50026;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cf17c_row0_col4 {\n",
              "  background-color: #016a38;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cf17c_row1_col0, #T_cf17c_row1_col4, #T_cf17c_row2_col0, #T_cf17c_row3_col1, #T_cf17c_row3_col2 {\n",
              "  background-color: #006837;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cf17c_row1_col1, #T_cf17c_row2_col1 {\n",
              "  background-color: #ab0626;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cf17c_row1_col2, #T_cf17c_row2_col2 {\n",
              "  background-color: #51b35e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cf17c_row2_col4 {\n",
              "  background-color: #bd1726;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_cf17c_row3_col0 {\n",
              "  background-color: #fdfebc;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_cf17c\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_cf17c_level0_col0\" class=\"col_heading level0 col0\" >macro_F1</th>\n",
              "      <th id=\"T_cf17c_level0_col1\" class=\"col_heading level0 col1\" >macro_precision</th>\n",
              "      <th id=\"T_cf17c_level0_col2\" class=\"col_heading level0 col2\" >macro_recall</th>\n",
              "      <th id=\"T_cf17c_level0_col3\" class=\"col_heading level0 col3\" >Количество классификаторов</th>\n",
              "      <th id=\"T_cf17c_level0_col4\" class=\"col_heading level0 col4\" >Скорость обучения (секунд)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_cf17c_level0_row0\" class=\"row_heading level0 row0\" >One-vs-Rest with Logistic Regression</th>\n",
              "      <td id=\"T_cf17c_row0_col0\" class=\"data row0 col0\" >0.397389</td>\n",
              "      <td id=\"T_cf17c_row0_col1\" class=\"data row0 col1\" >0.532561</td>\n",
              "      <td id=\"T_cf17c_row0_col2\" class=\"data row0 col2\" >0.434916</td>\n",
              "      <td id=\"T_cf17c_row0_col3\" class=\"data row0 col3\" >3</td>\n",
              "      <td id=\"T_cf17c_row0_col4\" class=\"data row0 col4\" >0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cf17c_level0_row1\" class=\"row_heading level0 row1\" >One-vs-One with Logistic Regression</th>\n",
              "      <td id=\"T_cf17c_row1_col0\" class=\"data row1 col0\" >0.413611</td>\n",
              "      <td id=\"T_cf17c_row1_col1\" class=\"data row1 col1\" >0.535071</td>\n",
              "      <td id=\"T_cf17c_row1_col2\" class=\"data row1 col2\" >0.441842</td>\n",
              "      <td id=\"T_cf17c_row1_col3\" class=\"data row1 col3\" >3</td>\n",
              "      <td id=\"T_cf17c_row1_col4\" class=\"data row1 col4\" >0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cf17c_level0_row2\" class=\"row_heading level0 row2\" >One-vs-One + Optuna with Logistic Regression</th>\n",
              "      <td id=\"T_cf17c_row2_col0\" class=\"data row2 col0\" >0.413611</td>\n",
              "      <td id=\"T_cf17c_row2_col1\" class=\"data row2 col1\" >0.535071</td>\n",
              "      <td id=\"T_cf17c_row2_col2\" class=\"data row2 col2\" >0.441842</td>\n",
              "      <td id=\"T_cf17c_row2_col3\" class=\"data row2 col3\" >3</td>\n",
              "      <td id=\"T_cf17c_row2_col4\" class=\"data row2 col4\" >2.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cf17c_level0_row3\" class=\"row_heading level0 row3\" >One-vs-Rest + Optuna with Logistic Regression</th>\n",
              "      <td id=\"T_cf17c_row3_col0\" class=\"data row3 col0\" >0.405606</td>\n",
              "      <td id=\"T_cf17c_row3_col1\" class=\"data row3 col1\" >0.709400</td>\n",
              "      <td id=\"T_cf17c_row3_col2\" class=\"data row3 col2\" >0.443286</td>\n",
              "      <td id=\"T_cf17c_row3_col3\" class=\"data row3 col3\" >3</td>\n",
              "      <td id=\"T_cf17c_row3_col4\" class=\"data row3 col4\" >2.724000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1d4143708c0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_metrics['Количество классификаторов'] = df_metrics['Количество классификаторов'].astype(int)\n",
        "display(df_metrics.style\n",
        "    .background_gradient(subset=['macro_F1', 'macro_precision', 'macro_recall'], cmap='RdYlGn')\n",
        "    .background_gradient(subset=['Скорость обучения (секунд)'], cmap='RdYlGn_r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Качество довольно низкое даже с optuna.\\\n",
        "Я хочу попробовать обучить random forest для оценки важности признаков. Я предполагаю, что выбранный набор признаков просто очень слабый"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.560474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.043536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>0.037481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>0.036716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.025790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.024565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.021256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.017384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.016205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.015235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.014917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.014645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0.014362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.014218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.014145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature  importance\n",
              "0         0    0.560474\n",
              "18       18    0.043536\n",
              "44       44    0.037481\n",
              "43       43    0.036716\n",
              "13       13    0.025790\n",
              "22       22    0.024565\n",
              "16       16    0.021256\n",
              "1         1    0.017384\n",
              "15       15    0.016205\n",
              "9         9    0.015235\n",
              "23       23    0.014917\n",
              "14       14    0.014645\n",
              "24       24    0.014362\n",
              "17       17    0.014218\n",
              "2         2    0.014145"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_transformed, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': range(X_train_transformed.shape[1]),  \n",
        "    'importance': rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "feature_importance.head(15) # для того чтоб понять масштаб проблемы, вывожу 15 лучших\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Визуализация\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['feature'].head(15).astype(str), \n",
        "         feature_importance['importance'].head(15))\n",
        "plt.xlabel('Важность признака')\n",
        "plt.title('Топ-15 самых важных признаков (RandomForest)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Признак 0: Marital status\n"
          ]
        }
      ],
      "source": [
        "if hasattr(X_train, 'columns'):\n",
        "    print(f\"Признак 0: {X_train.columns[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Странно, огромная важность у семейного положения, хотя корреляция таргета с ним (посчитана ниже) слабая. В остальном можно уверенно сказать, что **набор признаков действительно слабый**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Корреляция Marital status с таргетом: -0.094 (p-value: 0.0000)\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import pointbiserialr\n",
        "corr, p_value = pointbiserialr(X_train['Marital status'], y_train)\n",
        "print(f\"Корреляция Marital status с таргетом: {corr:.3f} (p-value: {p_value:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я решил посмотреть на permutation importance, так как RF importance не отражает реальной прогностической силы, завышает важность скоррелированных признаков. А **permutation importance устойчив к дисбалансу и отражает реальный вклад в прогноз, лучше для интерпретации**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Топ-5 по permutation importance:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>perm_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.050621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.004972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.004294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.003390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.003164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature  perm_importance\n",
              "0         0         0.050621\n",
              "13       13         0.004972\n",
              "15       15         0.004294\n",
              "18       18         0.003390\n",
              "11       11         0.003164"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "perm_importance = permutation_importance(\n",
        "    rf, X_test_transformed, y_test, \n",
        "    n_repeats=5, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "perm_df = pd.DataFrame({\n",
        "    'feature': range(X_train_transformed.shape[1]),\n",
        "    'perm_importance': perm_importance.importances_mean\n",
        "}).sort_values('perm_importance', ascending=False)\n",
        "\n",
        "print(\"Топ-5 по permutation importance:\")\n",
        "perm_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCxJ7e3QYsgF"
      },
      "source": [
        "Как вы объясните полученные результаты?\n",
        "\n",
        "__Ответ:__ **Набор признаков достаточно слабый, так как даже самый лучший признак дает только 5% улучшения**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075hgy9sP7QX"
      },
      "source": [
        "#### __Задание 15. Softmax регрессия__ (1 балл)\n",
        "\n",
        "Однако любознательные машинисты могут задаться вопросом \"А зачем нам вся эта шляпа, если у сигмоиды есть обобщение на случай многоклассовой классификации?\" Если вам понравилось считать градиенты в прошлом дз, или вам нравится обучать нейросети, этот пункт для вас. Здесь мы попробуем построить одну-единственную модель, которая будет всё предсказывать, а также сравним с вариантами выше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgBxUToxRPN8"
      },
      "source": [
        "Начнём с подсчёта лосса. Вспомним, что логистическая функция потерь это частный случай кросс-энтропии, её и будем пытаться оптимизировать.\n",
        "\n",
        "$$\n",
        "\\text{CE}(X, y) = -\\frac{1}{N}\\sum_i \\sum_k [y_i = k] \\log p(x_i = k)\n",
        "$$\n",
        "Вероятности в данном случае будем считать при помощи софтмакса, что есть общий случай сигмоиды\n",
        "\n",
        "$$\n",
        "p(x_i) = \\text{Softmax}(a(x_i)); \\quad\n",
        "\\text{Softmax}(x)_k = \\frac{e^{x_{k}}}{\\sum_j e^{x_{j}}} \\\\\n",
        "$$\n",
        "\n",
        "Предсказание модели на одном объекта будет делаться уже при помощи матрицы весов, посклоьку выходов несколько\n",
        "\n",
        "$$\n",
        "a(x_i) = x_i\\cdot W \\\\\n",
        "$$\n",
        "\n",
        "Ниже предлагается написать код для такой функции потерь. Если необходимо, модифицируйте шаблон по своему усмотрению (вспомогательные функции, новые аргументы, всё, что душа пожелает)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Downloading torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
            "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.5/241.3 MB 5.6 MB/s eta 0:00:44\n",
            "   ---------------------------------------- 1.8/241.3 MB 6.3 MB/s eta 0:00:39\n",
            "   ---------------------------------------- 2.6/241.3 MB 5.0 MB/s eta 0:00:48\n",
            "    --------------------------------------- 3.9/241.3 MB 5.5 MB/s eta 0:00:44\n",
            "    --------------------------------------- 4.7/241.3 MB 5.6 MB/s eta 0:00:43\n",
            "    --------------------------------------- 5.2/241.3 MB 4.9 MB/s eta 0:00:49\n",
            "   - -------------------------------------- 6.8/241.3 MB 5.1 MB/s eta 0:00:46\n",
            "   - -------------------------------------- 6.8/241.3 MB 5.1 MB/s eta 0:00:46\n",
            "   - -------------------------------------- 8.1/241.3 MB 4.6 MB/s eta 0:00:51\n",
            "   - -------------------------------------- 9.2/241.3 MB 4.7 MB/s eta 0:00:50\n",
            "   - -------------------------------------- 10.5/241.3 MB 4.8 MB/s eta 0:00:48\n",
            "   - -------------------------------------- 11.8/241.3 MB 5.0 MB/s eta 0:00:47\n",
            "   -- ------------------------------------- 12.8/241.3 MB 5.0 MB/s eta 0:00:46\n",
            "   -- ------------------------------------- 14.2/241.3 MB 5.1 MB/s eta 0:00:45\n",
            "   -- ------------------------------------- 15.5/241.3 MB 5.2 MB/s eta 0:00:44\n",
            "   -- ------------------------------------- 16.8/241.3 MB 5.3 MB/s eta 0:00:43\n",
            "   -- ------------------------------------- 18.1/241.3 MB 5.3 MB/s eta 0:00:43\n",
            "   --- ------------------------------------ 19.1/241.3 MB 5.3 MB/s eta 0:00:42\n",
            "   --- ------------------------------------ 20.4/241.3 MB 5.4 MB/s eta 0:00:42\n",
            "   --- ------------------------------------ 21.5/241.3 MB 5.4 MB/s eta 0:00:41\n",
            "   --- ------------------------------------ 22.8/241.3 MB 5.4 MB/s eta 0:00:41\n",
            "   --- ------------------------------------ 24.1/241.3 MB 5.5 MB/s eta 0:00:40\n",
            "   ---- ----------------------------------- 25.4/241.3 MB 5.5 MB/s eta 0:00:40\n",
            "   ---- ----------------------------------- 26.7/241.3 MB 5.5 MB/s eta 0:00:39\n",
            "   ---- ----------------------------------- 28.0/241.3 MB 5.6 MB/s eta 0:00:39\n",
            "   ---- ----------------------------------- 29.1/241.3 MB 5.6 MB/s eta 0:00:39\n",
            "   ----- ---------------------------------- 30.4/241.3 MB 5.6 MB/s eta 0:00:38\n",
            "   ----- ---------------------------------- 31.7/241.3 MB 5.6 MB/s eta 0:00:38\n",
            "   ----- ---------------------------------- 33.0/241.3 MB 5.6 MB/s eta 0:00:38\n",
            "   ----- ---------------------------------- 33.8/241.3 MB 5.6 MB/s eta 0:00:38\n",
            "   ----- ---------------------------------- 34.9/241.3 MB 5.6 MB/s eta 0:00:38\n",
            "   ----- ---------------------------------- 35.9/241.3 MB 5.6 MB/s eta 0:00:38\n",
            "   ------ --------------------------------- 37.0/241.3 MB 5.6 MB/s eta 0:00:37\n",
            "   ------ --------------------------------- 38.3/241.3 MB 5.6 MB/s eta 0:00:37\n",
            "   ------ --------------------------------- 39.6/241.3 MB 5.6 MB/s eta 0:00:37\n",
            "   ------ --------------------------------- 40.9/241.3 MB 5.6 MB/s eta 0:00:36\n",
            "   ------ --------------------------------- 41.9/241.3 MB 5.6 MB/s eta 0:00:36\n",
            "   ------- -------------------------------- 43.3/241.3 MB 5.6 MB/s eta 0:00:36\n",
            "   ------- -------------------------------- 44.6/241.3 MB 5.6 MB/s eta 0:00:35\n",
            "   ------- -------------------------------- 45.9/241.3 MB 5.6 MB/s eta 0:00:35\n",
            "   ------- -------------------------------- 46.9/241.3 MB 5.7 MB/s eta 0:00:35\n",
            "   ------- -------------------------------- 48.2/241.3 MB 5.7 MB/s eta 0:00:35\n",
            "   -------- ------------------------------- 49.5/241.3 MB 5.7 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 50.9/241.3 MB 5.7 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 52.2/241.3 MB 5.7 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 53.5/241.3 MB 5.7 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 54.5/241.3 MB 5.7 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 55.8/241.3 MB 5.7 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 57.1/241.3 MB 5.8 MB/s eta 0:00:32\n",
            "   --------- ------------------------------ 58.5/241.3 MB 5.8 MB/s eta 0:00:32\n",
            "   --------- ------------------------------ 59.8/241.3 MB 5.8 MB/s eta 0:00:32\n",
            "   ---------- ----------------------------- 61.1/241.3 MB 5.8 MB/s eta 0:00:32\n",
            "   ---------- ----------------------------- 62.4/241.3 MB 5.8 MB/s eta 0:00:31\n",
            "   ---------- ----------------------------- 63.7/241.3 MB 5.8 MB/s eta 0:00:31\n",
            "   ---------- ----------------------------- 65.0/241.3 MB 5.8 MB/s eta 0:00:31\n",
            "   ---------- ----------------------------- 66.3/241.3 MB 5.8 MB/s eta 0:00:31\n",
            "   ----------- ---------------------------- 67.4/241.3 MB 5.8 MB/s eta 0:00:30\n",
            "   ----------- ---------------------------- 68.7/241.3 MB 5.8 MB/s eta 0:00:30\n",
            "   ----------- ---------------------------- 69.7/241.3 MB 5.8 MB/s eta 0:00:30\n",
            "   ----------- ---------------------------- 71.0/241.3 MB 5.8 MB/s eta 0:00:30\n",
            "   ----------- ---------------------------- 72.1/241.3 MB 5.8 MB/s eta 0:00:30\n",
            "   ------------ --------------------------- 73.4/241.3 MB 5.8 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 74.7/241.3 MB 5.8 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 76.0/241.3 MB 5.8 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 77.3/241.3 MB 5.8 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 78.4/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 79.7/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 81.0/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 82.1/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 83.4/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 83.6/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 84.4/241.3 MB 5.8 MB/s eta 0:00:28\n",
            "   -------------- ------------------------- 85.5/241.3 MB 5.7 MB/s eta 0:00:28\n",
            "   -------------- ------------------------- 86.2/241.3 MB 5.7 MB/s eta 0:00:28\n",
            "   -------------- ------------------------- 87.3/241.3 MB 5.7 MB/s eta 0:00:28\n",
            "   -------------- ------------------------- 88.3/241.3 MB 5.7 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 89.4/241.3 MB 5.7 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 90.4/241.3 MB 5.7 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 91.5/241.3 MB 5.7 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 92.5/241.3 MB 5.7 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 93.3/241.3 MB 5.6 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 94.4/241.3 MB 5.6 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 95.4/241.3 MB 5.6 MB/s eta 0:00:26\n",
            "   --------------- ------------------------ 96.5/241.3 MB 5.6 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 97.5/241.3 MB 5.6 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 98.6/241.3 MB 5.6 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 99.6/241.3 MB 5.6 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 100.7/241.3 MB 5.6 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 101.7/241.3 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 102.8/241.3 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 104.1/241.3 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 105.1/241.3 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 106.2/241.3 MB 5.6 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 107.5/241.3 MB 5.6 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 108.8/241.3 MB 5.6 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 110.1/241.3 MB 5.6 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 111.1/241.3 MB 5.6 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 112.5/241.3 MB 5.6 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 113.5/241.3 MB 5.6 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 114.8/241.3 MB 5.6 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 116.1/241.3 MB 5.6 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 117.4/241.3 MB 5.6 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 118.5/241.3 MB 5.6 MB/s eta 0:00:22\n",
            "   ------------------- -------------------- 119.8/241.3 MB 5.6 MB/s eta 0:00:22\n",
            "   -------------------- ------------------- 121.1/241.3 MB 5.6 MB/s eta 0:00:22\n",
            "   -------------------- ------------------- 122.4/241.3 MB 5.6 MB/s eta 0:00:22\n",
            "   -------------------- ------------------- 123.5/241.3 MB 5.6 MB/s eta 0:00:21\n",
            "   -------------------- ------------------- 124.8/241.3 MB 5.6 MB/s eta 0:00:21\n",
            "   -------------------- ------------------- 126.1/241.3 MB 5.6 MB/s eta 0:00:21\n",
            "   --------------------- ------------------ 127.4/241.3 MB 5.6 MB/s eta 0:00:21\n",
            "   --------------------- ------------------ 128.5/241.3 MB 5.6 MB/s eta 0:00:21\n",
            "   --------------------- ------------------ 129.8/241.3 MB 5.6 MB/s eta 0:00:20\n",
            "   --------------------- ------------------ 130.8/241.3 MB 5.6 MB/s eta 0:00:20\n",
            "   --------------------- ------------------ 131.9/241.3 MB 5.6 MB/s eta 0:00:20\n",
            "   ---------------------- ----------------- 133.2/241.3 MB 5.6 MB/s eta 0:00:20\n",
            "   ---------------------- ----------------- 134.5/241.3 MB 5.6 MB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 135.8/241.3 MB 5.7 MB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 136.8/241.3 MB 5.7 MB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 137.9/241.3 MB 5.6 MB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 139.2/241.3 MB 5.6 MB/s eta 0:00:19\n",
            "   ----------------------- ---------------- 140.5/241.3 MB 5.7 MB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 141.6/241.3 MB 5.7 MB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 142.6/241.3 MB 5.7 MB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 143.9/241.3 MB 5.7 MB/s eta 0:00:18\n",
            "   ------------------------ --------------- 145.0/241.3 MB 5.7 MB/s eta 0:00:18\n",
            "   ------------------------ --------------- 146.3/241.3 MB 5.6 MB/s eta 0:00:17\n",
            "   ------------------------ --------------- 147.3/241.3 MB 5.7 MB/s eta 0:00:17\n",
            "   ------------------------ --------------- 148.6/241.3 MB 5.7 MB/s eta 0:00:17\n",
            "   ------------------------ --------------- 149.7/241.3 MB 5.6 MB/s eta 0:00:17\n",
            "   ------------------------ --------------- 150.7/241.3 MB 5.6 MB/s eta 0:00:17\n",
            "   ------------------------- -------------- 151.8/241.3 MB 5.6 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 152.8/241.3 MB 5.6 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 153.6/241.3 MB 5.6 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 154.7/241.3 MB 5.6 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 156.0/241.3 MB 5.6 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 157.0/241.3 MB 5.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 158.3/241.3 MB 5.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 159.4/241.3 MB 5.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 160.4/241.3 MB 5.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 162.0/241.3 MB 5.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 162.8/241.3 MB 5.6 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 164.1/241.3 MB 5.6 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 165.2/241.3 MB 5.6 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 166.5/241.3 MB 5.6 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 167.5/241.3 MB 5.6 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 168.8/241.3 MB 5.6 MB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 169.9/241.3 MB 5.6 MB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 171.2/241.3 MB 5.6 MB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 172.2/241.3 MB 5.6 MB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 173.5/241.3 MB 5.7 MB/s eta 0:00:12\n",
            "   ---------------------------- ----------- 174.6/241.3 MB 5.7 MB/s eta 0:00:12\n",
            "   ----------------------------- ---------- 175.9/241.3 MB 5.7 MB/s eta 0:00:12\n",
            "   ----------------------------- ---------- 176.9/241.3 MB 5.7 MB/s eta 0:00:12\n",
            "   ----------------------------- ---------- 178.3/241.3 MB 5.7 MB/s eta 0:00:12\n",
            "   ----------------------------- ---------- 179.3/241.3 MB 5.7 MB/s eta 0:00:11\n",
            "   ----------------------------- ---------- 180.6/241.3 MB 5.7 MB/s eta 0:00:11\n",
            "   ------------------------------ --------- 181.9/241.3 MB 5.7 MB/s eta 0:00:11\n",
            "   ------------------------------ --------- 183.2/241.3 MB 5.7 MB/s eta 0:00:11\n",
            "   ------------------------------ --------- 184.5/241.3 MB 5.7 MB/s eta 0:00:10\n",
            "   ------------------------------ --------- 185.6/241.3 MB 5.7 MB/s eta 0:00:10\n",
            "   ------------------------------ --------- 186.9/241.3 MB 5.7 MB/s eta 0:00:10\n",
            "   ------------------------------- -------- 188.0/241.3 MB 5.7 MB/s eta 0:00:10\n",
            "   ------------------------------- -------- 189.3/241.3 MB 5.7 MB/s eta 0:00:10\n",
            "   ------------------------------- -------- 190.3/241.3 MB 5.7 MB/s eta 0:00:09\n",
            "   ------------------------------- -------- 191.6/241.3 MB 5.7 MB/s eta 0:00:09\n",
            "   ------------------------------- -------- 192.4/241.3 MB 5.7 MB/s eta 0:00:09\n",
            "   -------------------------------- ------- 193.5/241.3 MB 5.7 MB/s eta 0:00:09\n",
            "   -------------------------------- ------- 194.8/241.3 MB 5.7 MB/s eta 0:00:09\n",
            "   -------------------------------- ------- 195.8/241.3 MB 5.6 MB/s eta 0:00:09\n",
            "   -------------------------------- ------- 196.9/241.3 MB 5.6 MB/s eta 0:00:08\n",
            "   -------------------------------- ------- 197.9/241.3 MB 5.6 MB/s eta 0:00:08\n",
            "   -------------------------------- ------- 199.0/241.3 MB 5.6 MB/s eta 0:00:08\n",
            "   --------------------------------- ------ 200.3/241.3 MB 5.6 MB/s eta 0:00:08\n",
            "   --------------------------------- ------ 201.3/241.3 MB 5.6 MB/s eta 0:00:08\n",
            "   --------------------------------- ------ 202.4/241.3 MB 5.6 MB/s eta 0:00:07\n",
            "   --------------------------------- ------ 203.4/241.3 MB 5.6 MB/s eta 0:00:07\n",
            "   --------------------------------- ------ 204.7/241.3 MB 5.6 MB/s eta 0:00:07\n",
            "   ---------------------------------- ----- 206.0/241.3 MB 5.6 MB/s eta 0:00:07\n",
            "   ---------------------------------- ----- 207.4/241.3 MB 5.6 MB/s eta 0:00:07\n",
            "   ---------------------------------- ----- 208.7/241.3 MB 5.6 MB/s eta 0:00:06\n",
            "   ---------------------------------- ----- 210.0/241.3 MB 5.6 MB/s eta 0:00:06\n",
            "   ----------------------------------- ---- 211.3/241.3 MB 5.6 MB/s eta 0:00:06\n",
            "   ----------------------------------- ---- 212.6/241.3 MB 5.6 MB/s eta 0:00:06\n",
            "   ----------------------------------- ---- 213.9/241.3 MB 5.6 MB/s eta 0:00:05\n",
            "   ----------------------------------- ---- 215.2/241.3 MB 5.6 MB/s eta 0:00:05\n",
            "   ----------------------------------- ---- 216.3/241.3 MB 5.6 MB/s eta 0:00:05\n",
            "   ------------------------------------ --- 217.6/241.3 MB 5.6 MB/s eta 0:00:05\n",
            "   ------------------------------------ --- 218.9/241.3 MB 5.6 MB/s eta 0:00:04\n",
            "   ------------------------------------ --- 220.2/241.3 MB 5.6 MB/s eta 0:00:04\n",
            "   ------------------------------------ --- 221.2/241.3 MB 5.6 MB/s eta 0:00:04\n",
            "   ------------------------------------ --- 222.6/241.3 MB 5.6 MB/s eta 0:00:04\n",
            "   ------------------------------------- -- 223.6/241.3 MB 5.6 MB/s eta 0:00:04\n",
            "   ------------------------------------- -- 224.9/241.3 MB 5.6 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 226.2/241.3 MB 5.6 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 227.3/241.3 MB 5.6 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 228.6/241.3 MB 5.6 MB/s eta 0:00:03\n",
            "   -------------------------------------- - 229.9/241.3 MB 5.6 MB/s eta 0:00:03\n",
            "   -------------------------------------- - 230.9/241.3 MB 5.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 232.3/241.3 MB 5.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 233.6/241.3 MB 5.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 234.6/241.3 MB 5.6 MB/s eta 0:00:02\n",
            "   ---------------------------------------  235.9/241.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  237.2/241.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  238.3/241.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  239.6/241.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  240.9/241.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  241.2/241.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 241.3/241.3 MB 5.6 MB/s eta 0:00:00\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 1.0/6.3 MB 5.6 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 2.4/6.3 MB 5.8 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 3.4/6.3 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 4.5/6.3 MB 5.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.2/6.3 MB 5.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.3/6.3 MB 5.2 MB/s eta 0:00:00\n",
            "Installing collected packages: sympy, torch\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "Successfully installed sympy-1.14.0 torch-2.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "AYsBvtxmTK5d"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable, Optional\n",
        "from torch.nn.functional import cross_entropy\n",
        "import torch\n",
        "\n",
        "def custom_ce(\n",
        "    y_pred: np.ndarray[float],\n",
        "    y_true: np.ndarray[int],\n",
        ") -> float:\n",
        "    \n",
        "    exp_pred = np.exp(y_pred - np.max(y_pred, axis=1, keepdims=True))  \n",
        "    probabilities = exp_pred / np.sum(exp_pred, axis=1, keepdims=True)\n",
        "\n",
        "    N = y_true.shape[0]\n",
        "    true_class_probs = probabilities[np.arange(N), y_true]\n",
        "    \n",
        "    loss = -np.mean(np.log(true_class_probs + 1e-8))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "JOK4eJXpSamh"
      },
      "outputs": [],
      "source": [
        "for _ in range(1000):\n",
        "\n",
        "    n_objects = np.random.randint(1, 100)\n",
        "    n_classes = np.random.randint(2, 20)\n",
        "    y_pred = np.random.normal(0, 1, (n_objects, n_classes))\n",
        "    y_true = np.random.randint(low=0, high=n_classes, size=(n_objects,))\n",
        "\n",
        "    your_ce = custom_ce(y_pred, y_true) \n",
        "    torch_ce = cross_entropy(torch.tensor(y_pred), torch.tensor(y_true, dtype=torch.long))\n",
        "    assert np.allclose(your_ce, torch_ce), \"Что-то пошло не так\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9MLDIQrT24U"
      },
      "source": [
        "Дальше самая интересная часть - нужно вывести производную этой функции потерь (на всякий случай уточним, что `torch` использовать нельзя, разве что для самопроверки). Полезные факты, которые вам могут пригодиться:\n",
        "\n",
        "- в матричном виде найти производную непросто, попробуйте сперва сделать это для одного объекта, обобщить будет полегче\n",
        "- логсофтмакс дифференцировать гораздо легче, чем просто софтмакс\n",
        "- не забывайте про правило дифференцирования сложной функции\n",
        "- поскольку веса в данном случае матрица, результат будет тоже матрица, учтите при сверке размерностей\n",
        "- если вы не придумали, как преобразовать индикаторы в векторный вид, сейчас самое время"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "tYHes6fVVO7s"
      },
      "outputs": [],
      "source": [
        "def ce_gradient(X: np.ndarray, W: np.ndarray, y: np.ndarray) -> np.ndarray[float]:\n",
        "    \n",
        "    N, D = X.shape\n",
        "    K = W.shape[1]\n",
        "    \n",
        "    \n",
        "    logits = X @ W\n",
        "    \n",
        "    \n",
        "    shifted_logits = logits - np.max(logits, axis=1, keepdims=True)\n",
        "    exp_logits = np.exp(shifted_logits)\n",
        "    probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)  \n",
        "    \n",
        "    \n",
        "    y_one_hot = np.eye(K)[y]  \n",
        "    \n",
        "    \n",
        "    gradient = (X.T @ (probs - y_one_hot)) / N\n",
        "    \n",
        "    return gradient\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8KP9v4WW6UL"
      },
      "source": [
        "Дальше дело за малым. Вспомните (или узнайте), как делается градиентный спуск, и дополните класс софтмакс-регрессии ниже. Здесь разумнее использовать критерий останова по итерациям, но логрег из `sklearn` устроен немного хитрее. Если хотите добавить еще критерии останова, какие-то другие параметры, то пожалуйста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "n133i8Nlc9Et"
      },
      "outputs": [],
      "source": [
        "class SoftmaxRegression:\n",
        "    def __init__(self, lr=1e-3, max_iter=10000, tol=1e-4, random_state=None):\n",
        "        self.W = None\n",
        "        self.max_iter = max_iter\n",
        "        self.lr = lr\n",
        "        self.tol = tol\n",
        "        self.random_state = random_state\n",
        "        self.loss_history = []\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        if self.random_state is not None:\n",
        "            np.random.seed(self.random_state)\n",
        "            \n",
        "        N, D = X.shape\n",
        "        self.classes_ = np.unique(y)\n",
        "        K = len(self.classes_)\n",
        "        \n",
        "       \n",
        "        self.W = np.random.normal(0, 0.01, (D, K))\n",
        "        \n",
        "        \n",
        "        y_indices = np.searchsorted(self.classes_, y)\n",
        "        \n",
        "        \n",
        "        prev_loss = float('inf')\n",
        "        \n",
        "        for i in range(self.max_iter):\n",
        "            logits = X @ self.W\n",
        "            shifted_logits = logits - np.max(logits, axis=1, keepdims=True)\n",
        "            exp_logits = np.exp(shifted_logits)\n",
        "            probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "            \n",
        "            true_class_probs = probs[np.arange(N), y_indices]\n",
        "            loss = -np.mean(np.log(true_class_probs + 1e-8))\n",
        "            self.loss_history.append(loss)\n",
        "            \n",
        "            if i > 0 and abs(prev_loss - loss) < self.tol:\n",
        "                print(f\"Converged at iteration {i}, loss: {loss:.6f}\")\n",
        "                break\n",
        "                \n",
        "            prev_loss = loss\n",
        "            \n",
        "            y_one_hot = np.eye(K)[y_indices]\n",
        "            gradient = (X.T @ (probs - y_one_hot)) / N\n",
        "            \n",
        "            self.W -= self.lr * gradient\n",
        "            \n",
        "            if i % 1000 == 0:\n",
        "                print(f\"Iteration {i}, loss: {loss:.6f}\")\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \n",
        "        logits = X @ self.W\n",
        "        shifted_logits = logits - np.max(logits, axis=1, keepdims=True)\n",
        "        exp_logits = np.exp(shifted_logits)\n",
        "        probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "        return probs\n",
        "    \n",
        "    def predict(self, X):\n",
        "       \n",
        "        probs = self.predict_proba(X)\n",
        "        predictions = np.argmax(probs, axis=1)\n",
        "        return self.classes_[predictions]\n",
        "    \n",
        "    def score(self, X, y):\n",
        "        \n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JSpEv6oXSIX"
      },
      "source": [
        "Обучите на тех же данных, что и выше, замерьте те же три параметра, плюс сравните значения кросс-энтропии для уже трёх моделей. Сравните модели между собой и выберите фаворита в данной задаче."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0, loss: 1.105717\n",
            "Converged at iteration 141, loss: 0.947216\n",
            "Обучение SoftmaxRegression заняло 0.131 секунд\n",
            "Размер матрицы весов: (45, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "start_softmax = time.time()\n",
        "\n",
        "softmax_model = SoftmaxRegression(\n",
        "    lr=0.1,                    # learning rate\n",
        "    max_iter=10000,            # максимальное число итераций\n",
        "    tol=1e-4,                  # критерий сходимости\n",
        "    random_state=42            # для воспроизводимости\n",
        ")\n",
        "\n",
        "softmax_model.fit(X_train_transformed, y_train)\n",
        "time_softmax = time.time() - start_softmax\n",
        "\n",
        "print(f'Обучение SoftmaxRegression заняло {round(time_softmax, 3)} секунд')\n",
        "print(f\"Размер матрицы весов: {softmax_model.W.shape}\")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_softmax = softmax_model.predict(X_test_transformed)\n",
        "\n",
        "# Метрики\n",
        "precision_per_class_softmax = precision_score(y_test, y_pred_softmax, average=None)\n",
        "recall_per_class_softmax = recall_score(y_test, y_pred_softmax, average=None)\n",
        "f1_per_class_softmax = f1_score(y_test, y_pred_softmax, average=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics.loc['SoftMax Regression'] = [\n",
        "    f1_per_class_softmax.mean(),\n",
        "    precision_per_class_softmax.mean(),\n",
        "    recall_per_class_softmax.mean(),\n",
        "    softmax_model.W.shape[1],           # классов столько, сколько выходов\n",
        "    round(time_softmax, 3)  \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b00d5_row0_col0 {\n",
              "  background-color: #f36b42;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row0_col1 {\n",
              "  background-color: #fff8b4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b00d5_row0_col2 {\n",
              "  background-color: #f16640;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row0_col4 {\n",
              "  background-color: #016a38;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row1_col0, #T_b00d5_row1_col4, #T_b00d5_row2_col0, #T_b00d5_row3_col1, #T_b00d5_row3_col2 {\n",
              "  background-color: #006837;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row1_col1, #T_b00d5_row2_col1 {\n",
              "  background-color: #fffab6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b00d5_row1_col2, #T_b00d5_row2_col2 {\n",
              "  background-color: #36a657;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row2_col4 {\n",
              "  background-color: #bd1726;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row3_col0 {\n",
              "  background-color: #d7ee8a;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_b00d5_row3_col4, #T_b00d5_row4_col0, #T_b00d5_row4_col1, #T_b00d5_row4_col2 {\n",
              "  background-color: #a50026;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_b00d5_row4_col4 {\n",
              "  background-color: #06733d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b00d5\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_b00d5_level0_col0\" class=\"col_heading level0 col0\" >macro_F1</th>\n",
              "      <th id=\"T_b00d5_level0_col1\" class=\"col_heading level0 col1\" >macro_precision</th>\n",
              "      <th id=\"T_b00d5_level0_col2\" class=\"col_heading level0 col2\" >macro_recall</th>\n",
              "      <th id=\"T_b00d5_level0_col3\" class=\"col_heading level0 col3\" >Количество классификаторов</th>\n",
              "      <th id=\"T_b00d5_level0_col4\" class=\"col_heading level0 col4\" >Скорость обучения (секунд)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_b00d5_level0_row0\" class=\"row_heading level0 row0\" >One-vs-Rest with Logistic Regression</th>\n",
              "      <td id=\"T_b00d5_row0_col0\" class=\"data row0 col0\" >0.397389</td>\n",
              "      <td id=\"T_b00d5_row0_col1\" class=\"data row0 col1\" >0.532561</td>\n",
              "      <td id=\"T_b00d5_row0_col2\" class=\"data row0 col2\" >0.434916</td>\n",
              "      <td id=\"T_b00d5_row0_col3\" class=\"data row0 col3\" >3</td>\n",
              "      <td id=\"T_b00d5_row0_col4\" class=\"data row0 col4\" >0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b00d5_level0_row1\" class=\"row_heading level0 row1\" >One-vs-One with Logistic Regression</th>\n",
              "      <td id=\"T_b00d5_row1_col0\" class=\"data row1 col0\" >0.413611</td>\n",
              "      <td id=\"T_b00d5_row1_col1\" class=\"data row1 col1\" >0.535071</td>\n",
              "      <td id=\"T_b00d5_row1_col2\" class=\"data row1 col2\" >0.441842</td>\n",
              "      <td id=\"T_b00d5_row1_col3\" class=\"data row1 col3\" >3</td>\n",
              "      <td id=\"T_b00d5_row1_col4\" class=\"data row1 col4\" >0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b00d5_level0_row2\" class=\"row_heading level0 row2\" >One-vs-One + Optuna with Logistic Regression</th>\n",
              "      <td id=\"T_b00d5_row2_col0\" class=\"data row2 col0\" >0.413611</td>\n",
              "      <td id=\"T_b00d5_row2_col1\" class=\"data row2 col1\" >0.535071</td>\n",
              "      <td id=\"T_b00d5_row2_col2\" class=\"data row2 col2\" >0.441842</td>\n",
              "      <td id=\"T_b00d5_row2_col3\" class=\"data row2 col3\" >3</td>\n",
              "      <td id=\"T_b00d5_row2_col4\" class=\"data row2 col4\" >2.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b00d5_level0_row3\" class=\"row_heading level0 row3\" >One-vs-Rest + Optuna with Logistic Regression</th>\n",
              "      <td id=\"T_b00d5_row3_col0\" class=\"data row3 col0\" >0.405606</td>\n",
              "      <td id=\"T_b00d5_row3_col1\" class=\"data row3 col1\" >0.709400</td>\n",
              "      <td id=\"T_b00d5_row3_col2\" class=\"data row3 col2\" >0.443286</td>\n",
              "      <td id=\"T_b00d5_row3_col3\" class=\"data row3 col3\" >3</td>\n",
              "      <td id=\"T_b00d5_row3_col4\" class=\"data row3 col4\" >2.724000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b00d5_level0_row4\" class=\"row_heading level0 row4\" >SoftMax Regression</th>\n",
              "      <td id=\"T_b00d5_row4_col0\" class=\"data row4 col0\" >0.393401</td>\n",
              "      <td id=\"T_b00d5_row4_col1\" class=\"data row4 col1\" >0.371450</td>\n",
              "      <td id=\"T_b00d5_row4_col2\" class=\"data row4 col2\" >0.432978</td>\n",
              "      <td id=\"T_b00d5_row4_col3\" class=\"data row4 col3\" >3</td>\n",
              "      <td id=\"T_b00d5_row4_col4\" class=\"data row4 col4\" >0.131000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1d423533080>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_metrics['Количество классификаторов'] = df_metrics['Количество классификаторов'].astype(int)\n",
        "display(df_metrics.style\n",
        "    .background_gradient(subset=['macro_F1', 'macro_precision', 'macro_recall'], cmap='RdYlGn')\n",
        "    .background_gradient(subset=['Скорость обучения (секунд)'], cmap='RdYlGn_r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6xDfck0cfrr"
      },
      "source": [
        "__Ответ__: One-vs-One показывает лучший результат. Худшей стала Softmax регрессия, но она достаточно близко к остальным. Я думаю что SoftMax проигрывает из-за того, что строит 1 глобальную модель,а OvO строит отдельные модели для каждой пары классов => **может лучше улавливать сложнные закономерности**.\\\n",
        "Главная проблема данной задачи - низкое качество признаков. Я думаю, что с таким набором добиться macro F1 > 0.5 почти нереально. **Нужен feature engineering или/и новые признаки**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xvhLtt4OP75Q",
        "RvWzOe4wP75T",
        "4VbJR0e3P75U"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
