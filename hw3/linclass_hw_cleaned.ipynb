{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTlmjXExP75I"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 4. Классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH11bAAV2SoV"
      },
      "source": [
        "### Общая информация\n",
        "Дата выдачи: 16.11.2024\n",
        "\n",
        "Мягкий дедлайн: 28.11.2024\n",
        "\n",
        "Жесткий дедлайн: 02.12.2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWjJuhqS3Ucc"
      },
      "source": [
        "### О задании\n",
        "\n",
        "В этом задании вы:\n",
        "- ознакомитесь с тем, что происходит \"внутри\" метода опорных векторов и логистической регрессии\n",
        "- познакомитесь с калибровкой вероятности\n",
        "- изучите методы трансформации переменных и методы отбора признаков\n",
        "- попробуете оценить экономический эффект модели\n",
        "\n",
        "----\n",
        "\n",
        "#### Самостоятельная оценка результатов\n",
        "\n",
        "Для удобства проверки, исходя из набора решенных задач, посчитайте свою максимальную оценку.\n",
        "\n",
        "**Оценка**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or0r6z5v1Mmt"
      },
      "source": [
        "### Оценивание и штрафы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CecLXG_w3zs0"
      },
      "source": [
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWDDNDyP75O"
      },
      "source": [
        "# Часть 1. SVM, LR и калибровка вероятностей (2 балла + 0.5 бонус)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyqoX1BNP75N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import polars as pl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "# pl.Config().set_tbl_rows(100)\n",
        "# pl.Config().set_tbl_cols(100)\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib_venn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvhLtt4OP75Q"
      },
      "source": [
        "#### __Задание 1.1  Сравнение методов__ (0.5 балла)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZw2aOq9P75O"
      },
      "source": [
        "Сгенерируем синтетические данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqkczFrQP75P"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# фиксируем random_state для воспроизводимости результатов\n",
        "X, y = make_classification(\n",
        "    n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdPx-lQbtaRe"
      },
      "source": [
        "__Случайный классификатор__\n",
        "\n",
        "Для начала зададим самую простую модель, которая на каждом объекте выдаёт случайный ответ. По тестовой выборке вычислим AUC-ROC, AUC-PR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gcSglAOjVn-",
        "outputId": "c593c237-1319-4b1d-dbdd-5877aa42cfb1"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "random_classifier = DummyClassifier(strategy='uniform', random_state=42).fit(X_train, y_train)\n",
        "y_random = random_classifier.predict_proba(X_test)[:,1]\n",
        "y_random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUhBXPre7jNi"
      },
      "source": [
        "**Вопрос:** решаем задачу бинарной классификации, но y\\_random содержит какие-то дробные числа, а не 0/1. Почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpIDxyuHH1bt"
      },
      "source": [
        "**Ответ**: Потому что мы используем метод predict_proba, который вычмсляет вероятность принадлежности объекта к положительному классу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnmZFwEYDVqx"
      },
      "source": [
        "*Ниже приведен **пример** работы* со встроенными функциями `sklearn` для отрисовки ROC и PR кривых, сохранения метрик. Пайплайн можно изменять как вам удобно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNJLhNj7DkLx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "-WHELzN6_fsQ",
        "outputId": "35a1ba3a-f588-4fee-ce1d-3190ddc9790b"
      },
      "outputs": [],
      "source": [
        "def depict_pr_roc(y_true, y_pred, classifier_name='Some Classifier', ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(11, 5))\n",
        "\n",
        "    print(classifier_name, 'metrics')\n",
        "    PrecisionRecallDisplay.from_predictions(y_true, y_pred, ax=ax[0], name=classifier_name)\n",
        "    print('AUC-PR: %.4f' % average_precision_score(y_true, y_pred))\n",
        "    ax[0].set_title(\"PRC\")\n",
        "    ax[0].set_ylim(0, 1.1)\n",
        "\n",
        "    RocCurveDisplay.from_predictions(y_true, y_pred, ax=ax[1], name=classifier_name)\n",
        "    print('AUC-ROC: %.4f' % roc_auc_score(y_true, y_pred))\n",
        "    ax[1].set_title(\"ROC\")\n",
        "    ax[1].set_ylim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.legend()\n",
        "    plt.show()  \n",
        "\n",
        "depict_pr_roc(y_test, y_random, 'Random Classifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "pSugCdAAEF2z",
        "outputId": "3c3cd961-bee5-4ca5-b607-6c51fc5e1b03"
      },
      "outputs": [],
      "source": [
        "# dataframe для сравнения\n",
        "# методов классификации по метрикам\n",
        "df_metrics = pd.DataFrame(\n",
        "    columns=['auc_pr', 'roc_auc_score', 'reg_const']\n",
        ")\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_random)\n",
        "# добавление очередной строки с характеристиками метода\n",
        "df_metrics.loc['Random Classifier'] = [\n",
        "      average_precision_score(y_test, y_random),\n",
        "      roc_auc_score(y_test, y_random),\n",
        "      0,\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "df_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IwDobmQtW2P"
      },
      "source": [
        "__Support Vector Machine (Linear Kernel)__\n",
        "\n",
        "Обучите метод опорных векторов.\n",
        "\n",
        "Подберите параметр регуляризации `C` с точки зрения AUC-PR (можете воспользоваться кросс-валидацией или отделить валидационную выборку от обучающей).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Я решил подбирать с помощью кросс-валидации**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyjF-qc3P75Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc = SVC(probability=True)\n",
        "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=2, scoring='average_precision') # 5 фолдов, average_precision - аналог pr-auc\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fapa63xlP75R"
      },
      "source": [
        "  На тестовой части:\n",
        "  - постройте ROC и PR кривые,\n",
        "  - посчитайте AUC-ROC, AUC-PR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred_svc = grid_search.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "depict_pr_roc(y_test, y_test_pred_svc, 'SVC (C=1000)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_svc)\n",
        "pr_auc = auc(recall_vals, precision_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'На тестовой выборке AUC-ROC = {round(roc_auc_score(y_test, y_test_pred_svc), 5)}')\n",
        "print(f'На тестовой выборке AUC-PR = {round(pr_auc, 5)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics.loc['SVC'] = [\n",
        "      round(pr_auc, 5),\n",
        "      round(roc_auc_score(y_test, y_test_pred_svc), 5),\n",
        "      1000,\n",
        "]\n",
        "\n",
        "df_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTvgDyaFhkYz"
      },
      "source": [
        "Проанализируйте, как себя ведут обе кривые:\n",
        "- Что происходит при увеличении порога? Как бы вы это проинтерпретировали?\n",
        "- Монотонные ли кривые? Как вы это объясните?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **При увеличении порога**:\n",
        "\n",
        "**ROC кривая**: двигаясь справа налево, мы увеличиваем порог => более строго относим объекты к положительному классу => FPR падает, так как мы наращиваем свою увереннность в объектах, которые называем положительными.\\\n",
        "При этом мы упускаем много реально положительных объектов, которые имели веорятность ниже заданного нами высокого порога. \n",
        "\n",
        "**PR кривая**: при увеличении порога мы двигаемся справа налево. Recall монотонно уменьшается, так как FN растет (мы относим многие объекты с большой уверенностью модели в том, что они положительного класса, к отрицательному классу). Precision растет, но не монотонно.\n",
        "\n",
        "#### **Монотонность:**\n",
        "При уменьшении порога классификации, TPR и FPR могут только увеличиваться или оставаться неизменными => ROC кривая монотонно неубывающая.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "В целом ROC-AUC демонстрирует качество разделения обоих классов, а PR-AUC качестов предсказания положительного класса\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEoGp5EDtIzW"
      },
      "source": [
        "Сравните AUC-ROC и AUC-PR для вашей модели с этими же метриками для случайного классификатора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnRTMhsm6Hvv"
      },
      "source": [
        "Наша модель намного лучше случайного классификатора, так как у нее и roc-auc и auc-pr на тестовой выборке близки к 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln5VaZE_P75S"
      },
      "source": [
        "__Logistic Regression__\n",
        "\n",
        "\n",
        "Аналогичное задание для логистической регрессии с L2 регуляризатором:\n",
        "\n",
        "\n",
        "*   подберите гиперпараметр C, используя метрику AUC-PR\n",
        "*   нарисуйте ROC, PR кривые для тестовой части\n",
        "*   выведите метрики для тестовых данных и сравните их с результатами случайного классификатора\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1TlamoBP75S"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LogReg = LogisticRegression(penalty='l2')\n",
        "grid_search_lr = GridSearchCV(LogReg, param_grid, cv=5, verbose=2, scoring='average_precision') # 5 фолдов, average_precision - аналог pr-auc\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred_logreg = grid_search_lr.predict_proba(X_test)[:,1]\n",
        "\n",
        "depict_pr_roc(y_test, y_test_pred_logreg, 'SVC (C=0.001)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr = auc(recall_vals, precision_vals)\n",
        "\n",
        "\n",
        "print(f'На тестовой выборке AUC-ROC = {round(roc_auc_score(y_test, y_test_pred_logreg), 5)}')\n",
        "print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr, 5)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics.loc['Logistic Regression'] = [\n",
        "      round(pr_auc_lr, 5),\n",
        "      round(roc_auc_score(y_test, y_test_pred_logreg), 5),\n",
        "      0.001,\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "display(df_metrics.style\n",
        "    .background_gradient(subset=['auc_pr', 'roc_auc_score'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На тестовых данных SVC заметно опережает Logreg => **в данных скорее всего есть сложные, нелинейные зависимости, которые лог регрессии сложнее распознать**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnj5PG1Rm5qX"
      },
      "source": [
        "Нарисуйте ROC, PR кривые для тестовой части для всех 3 классификаторов на одном графике"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**В создании этого графика мне помог deepseek**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fpr1, tpr1, _ = roc_curve(y_test, y_random)\n",
        "auc1 = auc(fpr1, tpr1)\n",
        "fig.add_trace(go.Scatter(x=fpr1, y=tpr1, \n",
        "                         name=f'Random Classifier (AUC = {auc1:.3f})',\n",
        "                         line=dict(color='#FF5252', width=3)))\n",
        "\n",
        "\n",
        "fpr2, tpr2, _ = roc_curve(y_test, y_test_pred_svc)\n",
        "auc2 = auc(fpr2, tpr2)\n",
        "fig.add_trace(go.Scatter(x=fpr2, y=tpr2,\n",
        "                         name=f'SVC (AUC = {auc2:.3f})',\n",
        "                         line=dict(color='#2196F3', width=3, dash='dash')))\n",
        "\n",
        "\n",
        "fpr3, tpr3, _ = roc_curve(y_test, y_test_pred_logreg)\n",
        "auc3 = auc(fpr3, tpr3)\n",
        "fig.add_trace(go.Scatter(x=fpr3, y=tpr3,\n",
        "                         name=f'Logistic Regression (AUC = {auc3:.3f})',\n",
        "                         line=dict(color='#6A0DAD', width=3)))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='<b>ROC кривые разных классификаторов</b>',\n",
        "    xaxis_title='False Positive Rate',\n",
        "    yaxis_title='True Positive Rate',\n",
        "    width=1200,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# график можно посмотреть в ROC_curves_different_classifiers.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "pr1, rec1, _ = precision_recall_curve(y_test, y_random)\n",
        "as1 = average_precision_score(y_test, y_random)\n",
        "fig.add_trace(go.Scatter(x=rec1, y=pr1, \n",
        "                         name=f'Random Classifier (AUC-PR = {as1:.3f})',\n",
        "                         line=dict(color='#FF5252', width=3)))\n",
        "\n",
        "\n",
        "pr2, rec2, _ = precision_recall_curve(y_test, y_test_pred_svc)\n",
        "as2 = average_precision_score(y_test, y_test_pred_svc)\n",
        "fig.add_trace(go.Scatter(x=rec2, y=pr2,\n",
        "                         name=f'SVC (AUC-PR = {as2:.3f})',\n",
        "                         line=dict(color='#2196F3', width=3, dash='dash')))\n",
        "\n",
        "\n",
        "pr3, rec3, _ = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "as3 = average_precision_score(y_test, y_test_pred_logreg)\n",
        "fig.add_trace(go.Scatter(x=rec3, y=pr3,\n",
        "                         name=f'Logistic Regression (AUC-PR = {as3:.3f})',\n",
        "                         line=dict(color='#6A0DAD', width=3)))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='<b>PR кривые разных классификаторов</b>',\n",
        "    xaxis_title='Recall',\n",
        "    yaxis_title='Precision',\n",
        "    width=1200,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# график можно посмотреть в PR_curves_different_classifiers.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khlorKXtr1Sy"
      },
      "source": [
        "**Вопрос:** Сравните результаты LR и SVM с точки зрения всех вычисленных критериев качества, объясните различия (если они есть).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "round(0.983990 - 0.833600, 4), round(0.98652 - 0.84533, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.sum()/len(y_train), y_test.sum()/len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un_w7BMZIAf2"
      },
      "source": [
        "**Ответ:** в общем разделении классов у SVM большое преимущество (AUC-ROC больше на 0.14).\\\n",
        "Разница в PR-AUC больше, значит преимущество SVM в отделении положительного класса больше.\\\n",
        "В целом здесь у SVC почти идеальное качество, у LR просто хорошее.\\\n",
        "Если выбирать из них, то почти во всех случаях для подобной задачи SVM лучше. LR лучше подходит только если важна интерпретируемость или ограничены вычислительные ресурсы (LR обучается быстрее).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvWzOe4wP75T"
      },
      "source": [
        "#### __Задание 1.2. Визуализация в подходах SVM, LR__ (0.5 балла)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWS1NfYwBbQ_"
      },
      "source": [
        "В названии метода опорных векторов присутствуют некоторые \"опорные векторы\". По сути, это объекты из обучающей выборки, которые задали положение разделяющей гиперплоскости.\n",
        "\n",
        "* Сгенерируйте синтетические данные с помощью `make_classification` __с 2 признаками__, обучите на нём метод опорных векторов. Не забудьте зафиксировать seed для воспроизводимости\n",
        "\n",
        "* Визуализируйте разделяющую прямую, все объекты и выделите опорные векторы. Ниже есть шаблоны, можете воспользоваться ими, либо написать своё"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIS-aGxi-Nr0"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=10000,          \n",
        "    n_features=2,            \n",
        "    n_informative=2,         #Оба признака информативные\n",
        "    n_redundant=0,           \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Решил не делить, так как все равно не нужна тестовая выборка\n",
        "\n",
        "svm_model = SVC(kernel='linear', C=1000.0, random_state=42)\n",
        "svm_model.fit(X, y)\n",
        "\n",
        "# Получаем опорные векторы\n",
        "support_vectors = svm_model.support_vectors_\n",
        "support_vector_indices = svm_model.support_\n",
        "\n",
        "print(f\"Количество опорных векторов: {len(support_vectors)}\")\n",
        "print(f\"Индексы опорных векторов: {support_vector_indices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "9jA3GbO9-wcU",
        "outputId": "bfe76c4d-7958-470d-bbb2-87c779d3fda0"
      },
      "outputs": [],
      "source": [
        "def plot_svm_2D(X, y, model,  plot_support=True):\n",
        "\n",
        "    # создал сетку\n",
        "    xx = np.linspace(X[:,0].min(), X[:,0].max(), 30)\n",
        "    yy = np.linspace(X[:,1].min(), X[:,1].max(), 30)\n",
        "    YY, XX = np.meshgrid(yy, xx)\n",
        "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "\n",
        "    # Ответы модели для сетки для отрисовки разделяющей прямой\n",
        "    Z = model.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "    plt.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
        "\n",
        "    # Отрисовал выборку\n",
        "    plt.scatter(\n",
        "        X[y == 0, 0], X[y == 0, 1],  # Класс 0\n",
        "        c='blue', label='Class 0', alpha=0.7\n",
        "    )\n",
        "    plt.scatter(\n",
        "        X[y == 1, 0], X[y == 1, 1],  # Класс 1  \n",
        "        c='red', label='Class 1', alpha=0.7\n",
        "    )\n",
        "\n",
        "    # Отрисовал опорные векторы\n",
        "    if plot_support:\n",
        "        plt.scatter(\n",
        "            model.support_vectors_[:, 0],  # X координаты опорных векторов\n",
        "            model.support_vectors_[:, 1],  # Y координаты опорных векторов\n",
        "            label='support vectors',\n",
        "            s=100,\n",
        "            linewidth=1,\n",
        "            edgecolor=\"blue\",\n",
        "            facecolors='none'\n",
        "        )\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_svm_2D(X, y, svm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdMs4iQAIYpu"
      },
      "source": [
        "**Вопрос:** какие объекты выделяются как \"опорные\"?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dplr4chfIXnm"
      },
      "source": [
        "**Ответ:** опорными становятся объекты, лежащие на границе зазора или внутри.\\\n",
        "Это наиболее информативные объекты, которые находятся ближе всего к разделяющей границе и определяют положение разделяющей гиперплоскости.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfpVN70PP75U"
      },
      "source": [
        "В отличие от метода опорных векторов, логистическая регрессия не пытается построить разделяющую гиперплоскость с максимальным отступом, а приближает в каждой точке пространства объектов вероятность положительных ответов $p(y=+1|x)$. Попробуйте нарисовать это распределение на плоскости, не забудьте отметить на ней все объекты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg_model = LogisticRegression(penalty='l2', C=0.001, verbose=2, random_state=42)\n",
        "logreg_model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "k5D2jq87f3MC",
        "outputId": "5a04f790-e90b-4f08-d25b-dd2f553d9d8d"
      },
      "outputs": [],
      "source": [
        "def plot_logreg_2D(X, y, model):\n",
        "\n",
        "    # создали сетку\n",
        "    xx = np.linspace(X[:,0].min(), X[:,0].max(), 100)\n",
        "    yy = np.linspace(X[:,1].min(), X[:,1].max(), 100)\n",
        "    YY, XX = np.meshgrid(yy, xx)\n",
        "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "\n",
        "    # Ответы модели для сетки для отрисовки распределения\n",
        "    Z = model.predict_proba(xy)[:, 1]\n",
        "    Z = Z.reshape((xx.shape[0], -1)).T\n",
        "\n",
        "    image = plt.imshow(\n",
        "        Z,\n",
        "        interpolation='nearest',\n",
        "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "        aspect='auto',\n",
        "        origin='lower',\n",
        "        cmap=plt.cm.PuOr_r\n",
        "    )\n",
        "\n",
        "    plt.scatter(\n",
        "        X[y == 0, 0], X[y == 0, 1],  # Класс 0\n",
        "        c='blue', label='Class 0', alpha=0.8, s=50, edgecolors='white'\n",
        "    )\n",
        "    plt.scatter(\n",
        "        X[y == 1, 0], X[y == 1, 1],  # Класс 1\n",
        "        c='red', label='Class 1', alpha=0.8, s=50, edgecolors='white'\n",
        "    )\n",
        "\n",
        "    # Добавляю линию уровня вероятности 0.5 (граница решения)\n",
        "    contour = plt.contour(XX, YY, Z, levels=[0.5], colors='black', linewidths=2)\n",
        "    plt.clabel(contour, inline=True, fontsize=12, fmt='p=0.5')\n",
        "\n",
        "    # Добавляю дополнительные уровни вероятности для наглядности\n",
        "    plt.contour(XX, YY, Z, levels=[0.25, 0.75], colors='gray', linewidths=1, linestyles='--')\n",
        "    \n",
        "    plt.colorbar(image, label='Вероятность класса 1: p(y=+1|x)')\n",
        "    plt.xlabel('Признак 1')\n",
        "    plt.ylabel('Признак 2')\n",
        "    plt.title('Логистическая регрессия: распределение вероятностей')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_logreg_2D(X, y, logreg_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ-Um7-6JnAp"
      },
      "source": [
        "**Вопрос:** Как на картинке визуализирована область, где модель не уверена ($p(y=+1|x) = 0.5$)? Как это обосновать теоритечески?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAAF0HiaIh9Z"
      },
      "source": [
        "**Ответ:** Область с вероятностью положительного класса = 0.5 визуализирована на картинке как белая линия.\\\n",
        "Сигмоида имеет наибольшую производную при P(1) = 0.5 => в этой области при небольшом изменении z вероятность принадлежности к положительному классу сильно меняется.\\\n",
        "Когда P(1) = 0.5, энтропия наибольшая => максимальная неопределеннось\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VbJR0e3P75U"
      },
      "source": [
        "#### __Задание 2. Калибровка вероятностей__ (1 балл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8taLYSgBd9u"
      },
      "source": [
        "Перейдём к оценке качества выдаваемых алгоритмами вероятностей. Начнём с калибровочных кривых.\n",
        "\n",
        "Допустим, алгоритм возвращает некоторые числа от нуля до единицы. Хорошо ли они оценивают вероятность?\n",
        "\n",
        "Хорошо откалиброванный  классификатор должен выдавать значения так, чтобы среди образцов, для которых он дал значение, близкое к $\\alpha$, примерно $\\alpha * 100 \\%$ фактически принадлежали к положительному классу. (Например, если классификатор выдает 0.3 для некоторых, то 30% из них должны принадлежать классу 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRBGtMArIxMc"
      },
      "source": [
        "Для построения калибровочной криовой используем следующий алгоритм:\n",
        "\n",
        "Разобьем отрезок $[0, 1]$ на несколько маленьких отрезков одинаковой длины.\n",
        "\n",
        "Рассмотрим $i$-й отрезок с границами $[a_i, b_i]$ и предсказания $p_1, p_2, \\dots, p_k$, которые попали в него. Пусть им соответствуют истинные ответы $y_1, y_2, \\dots, y_k$. Если алгоритм выдает корректные вероятности, то среди этих истинных ответов должно быть примерно $(a_i + b_i) / 2$ единиц. Иными словами, если нарисовать кривую, у которой по оси X отложены центры отрезков, а по оси Y — доли единичных ответов этих в отрезках, то она должна оказаться диагональной.\n",
        "\n",
        "Ниже приведена функция, которая должна рисовать такие кривые. В ней допущено две ошибки — найдите и исправьте их."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R75uefZuP75V"
      },
      "outputs": [],
      "source": [
        "#def plot_calibration_curve(y_test, preds):\n",
        " #   bin_middle_points = []\n",
        "  #  bin_real_ratios = []\n",
        "   # n_bins = 10\n",
        "    #for i in range(n_bins):\n",
        "     #   l = 1.0 / n_bins * i\n",
        "      #  r = 1.0 / n_bins * (i + 1)\n",
        "       # bin_middle_points.append((l - r) / 2)\n",
        "       # bin_real_ratios.append(np.min(y_test[(preds >= l) & (preds < r)] == 1))\n",
        "    #plt.figure(figsize=(6,6))\n",
        "    #plt.plot(bin_middle_points, bin_real_ratios)\n",
        "    #plt.ylim([-0.05, 1.05])\n",
        "    #plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_calibration_curve(y_test, preds, method='SVC', color1 = 'purple'):\n",
        "    bin_middle_points = []\n",
        "    bin_real_ratios = []\n",
        "    n_bins = 10\n",
        "    y_test = np.array(y_test).flatten()\n",
        "    preds = np.array(preds).flatten()\n",
        "    \n",
        "    for i in range(n_bins):\n",
        "        l = i / n_bins\n",
        "        r = (i + 1) / n_bins\n",
        "        bin_middle_points.append((l + r) / 2)\n",
        "        \n",
        "\n",
        "        if i == n_bins - 1:\n",
        "            mask = (preds >= l) & (preds <= r)\n",
        "        else:\n",
        "            mask = (preds >= l) & (preds < r)\n",
        "        \n",
        "\n",
        "        mask = np.array(mask).flatten()\n",
        "        \n",
        "        if mask.ndim > 1:\n",
        "            mask = mask.flatten()\n",
        "            \n",
        "        n_in_bin = np.sum(mask)\n",
        "        \n",
        "        if n_in_bin > 0:\n",
        " \n",
        "            y_in_bin = y_test[mask]\n",
        "            ratio = np.mean(y_in_bin == 1)\n",
        "            bin_real_ratios.append(ratio)\n",
        "        else:\n",
        "            bin_real_ratios.append(0.0)\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.plot(bin_middle_points, bin_real_ratios, color=color1)\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray') # идеальная калибровка\n",
        "    plt.ylim([-0.05, 1.05])\n",
        "    plt.grid()\n",
        "    plt.xlabel('Предсказанная вероятность принадлежности к положительному классу',fontsize =12)\n",
        "    plt.ylabel('Реальная вероятность принадлежности к положительному классу', fontsize =12)\n",
        "    plt.title(f'Калибровочная кривая для {method}', fontsize =14, pad=15)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R13YCkxMO_R4"
      },
      "source": [
        "Сгенерируйте синтетические данные аналогично использованным в самом первом задании. Постройте калибровочные кривые на тестовой части для логистической регрессии и метода опорных векторов (не забудьте перевести его предсказания в $[0;1]$).\n",
        "\n",
        "Отрисуйте калибровочную кривую идеально откалиброванной модели (диагональ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc = SVC(probability=True)\n",
        "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=2, scoring='average_precision') # 5 фолдов, average_precision - аналог pr-auc\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc_pred_probs_test = grid_search.predict_proba(X_test)[:,1] # получаю вероятности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LogReg = LogisticRegression(penalty='l2')\n",
        "grid_search_lr = GridSearchCV(LogReg, param_grid, cv=5, verbose=2, scoring='average_precision') # 5 фолдов, average_precision - аналог pr-auc\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred_logreg_probs = grid_search_lr.predict_proba(X_test)[:,1] # получаю вероятности положительного класса\n",
        "y_test_pred_logreg_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plot_calibration_curve(y_test, svc_pred_probs_test, method='SVC', color1 = 'purple')\n",
        "\n",
        "\n",
        "#plot_calibration_curve(y_test, y_test_pred_logreg_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_calibration_curve(y_test, y_test_pred_logreg_probs, method='Logistic Regression', color1 = 'orange')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t15IAX7GPJjF"
      },
      "source": [
        "**Вопрос**: хорошо ли откалиброваны кривые для SVM, логистической регрессии? Подумайте, как это следует из вида кривой\n",
        "\n",
        "**Ответ:** кривая для Логрега откалибрована лучше, чем кривая для SVM, так как она в среднем менее удалена от кривой идеально откалиброванной модели (диагональ).\\\n",
        "Это ожидаемо, так как Логрег концентрируется на получении верных вероятностей, а SVM - на верном прогнозе класса\n",
        "\n",
        "Из формальных способов в этом убедиться есть знакомый вам LogLoss, который напрямую оценивает вероятности,\n",
        "$$\\text{LogLoss} = -\\frac{1}{N}\\sum_{i} \\sum_{k \\in {0. 1}}\\log p_k[y_i = k]$$\n",
        "а так же BrierScore, который подсчитывает отклонение между получившейся вероятностью и реальным значением таргета.\n",
        "$$\\text{BrierScore} = \\frac{1}{N}\\sum_{i} (p_i - y_i)^2$$\n",
        "Посмотрите на них тоже и сделайте вывод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "logloss_svc = log_loss(y_test, svc_pred_probs_test)\n",
        "logloss_logreg = log_loss(y_test, y_test_pred_logreg_probs)\n",
        "\n",
        "round(logloss_svc, 4), round(logloss_logreg, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Согласно LogLoss SVC лучше откалибрована, несмотря на кажущееся преимущество логрега по визуализациям кривых.\\\n",
        "Это нессответствие происходит потому, что LogLoss оцениает индивидуально калибровку каждого объекта, а кривая по батчам.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ8d-pl26rQU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "brier_svc = brier_score_loss(y_test, svc_pred_probs_test)\n",
        "brier_lr = brier_score_loss(y_test, y_test_pred_logreg_probs)\n",
        "\n",
        "round(brier_svc, 4), round(brier_lr, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_calibr = pd.DataFrame(\n",
        "    columns=['Logloss', 'Brier Score', 'Количество фолдов', 'Метод калибровки']\n",
        ")\n",
        "\n",
        "df_metrics_calibr.loc['SVC '] = [\n",
        "      round(logloss_svc, 4),\n",
        "      round(brier_svc, 4),\n",
        "      5,\n",
        "      ' '\n",
        "]\n",
        "\n",
        "df_metrics_calibr.loc['Log Reg '] = [\n",
        "      round(logloss_logreg, 4),\n",
        "      round(brier_lr, 4),\n",
        "      5,\n",
        "      ' '\n",
        "]\n",
        "\n",
        "df_metrics_calibr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Исходя из Brier Score у SVC отличная калибровка, а Логрег требует дополнительной калибровки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgANQZyhPHIX"
      },
      "source": [
        "Изучите распределение ответов классификаторов при помощи гистограмм"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(12, 8), dpi=100)\n",
        "sns.kdeplot(\n",
        "    data=svc_pred_probs_test,\n",
        "    color=\"purple\",\n",
        "    label=\"Оцененные с помощью SVC вероятности\",\n",
        "    linewidth=2,\n",
        "    fill=True,\n",
        "    alpha=0.3,\n",
        ")\n",
        "\n",
        "sns.kdeplot(\n",
        "    data=y_test_pred_logreg_probs,\n",
        "    color=\"orange\",\n",
        "    label=\"Оцененные с помощью Логистической регрессии вероятности\",\n",
        "    linewidth=2,\n",
        "    fill=True,\n",
        "    alpha=0.3,\n",
        ")\n",
        "\n",
        "plt.title(\"Сравнение распределения ответов классификаторов\",fontsize=16, pad=20)\n",
        "plt.xlabel(\"Оцененная вероятность принадлежности к положительному классу\")\n",
        "plt.ylabel(\"Частота\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ga-L4CPK_O"
      },
      "source": [
        "**Вопрос:** Чем они различаются? Чем вы можете объяснить это?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOmrLYqdPP_0"
      },
      "source": [
        "**Ответ:** у ответов SVC бимодальное распределение, оно более уверенное. У ответов Логрега распределение похоже на равномерное, оно более осторожное с точки зрения оценивания неопределенности."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9-6ClfaP75W"
      },
      "source": [
        "Воспользуйтесь `CalibratedClassifierCV` из `sklearn` для калибровки вероятностей метода опорных векторов на обучении и постройте с его помощью  предсказания для тестовой выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вопрос:** Улучшились ли калибровочная кривая и качество калибровки?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR3pVlSNP75W"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# я решил применить трехчастную кросс-валидацию\n",
        "calibrated_svc = CalibratedClassifierCV(\n",
        "    estimator=SVC(probability=False, random_state=42),\n",
        "    method='sigmoid',\n",
        "    cv=3  \n",
        ")\n",
        "\n",
        "calibrated_svc.fit(X_train, y_train) # обучаю на трейне\n",
        "\n",
        "calibrated_probs = calibrated_svc.predict_proba(X_test) # предсказываю на тесте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "calibrated_probs[:,1][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_calibration_curve(y_test, calibrated_probs[:,1], method='откалиброванного SVC', color1 = 'purple')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Ответ:** **Калибровочная кривая улучшилась!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Посмотрим на качество калибровки:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logloss_svc_calibrated = log_loss(y_test, calibrated_probs[:,1])\n",
        "\n",
        "brier_svc_calibrated = brier_score_loss(y_test, calibrated_probs[:,1])\n",
        "\n",
        "round(logloss_svc_calibrated, 4), round(brier_svc_calibrated, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_calibr.loc['SVC с калибровкой'] = [\n",
        "      round(logloss_svc_calibrated, 4),\n",
        "      round(brier_svc_calibrated, 4),\n",
        "      3,\n",
        "      'sigmoid'\n",
        "]\n",
        "\n",
        "df_metrics_calibr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "По Brier score и logloss нет улучшшения. Попробую подобрать **оптимальное количество фолдов и вид калибровки**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#methods = ['sigmoid', 'isotonic']\n",
        "#cvs = [3, 5]\n",
        "\n",
        "param_grid_calibrated_svc = {\n",
        "    'method': ['sigmoid', 'isotonic'],\n",
        "    'cv': [3, 5]\n",
        "}\n",
        "\n",
        "\n",
        "calibrated_svc = CalibratedClassifierCV(\n",
        "    estimator=SVC(probability=False, random_state=42),\n",
        "  #  method='sigmoid',\n",
        " #   cv=3  \n",
        ")\n",
        "\n",
        "grid_search_calibrated_svc = GridSearchCV(calibrated_svc, param_grid_calibrated_svc, verbose=2, scoring='average_precision') \n",
        "grid_search_calibrated_svc.fit(X_train, y_train)\n",
        "\n",
        "#calibrated_svc.fit(X_train, y_train) # обучаю на трейне\n",
        "\n",
        "calibrated_probs_upd = grid_search_calibrated_svc.predict_proba(X_test) # предсказываю на тесте\n",
        "\n",
        "logloss_svc_calibrated_upd = log_loss(y_test, calibrated_probs_upd[:,1])\n",
        "\n",
        "brier_svc_calibrated_upd = brier_score_loss(y_test, calibrated_probs_upd[:,1])\n",
        "\n",
        "round(logloss_svc_calibrated_upd, 4), round(brier_svc_calibrated_upd, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Лучшими параметрами оказались: количество фолдов при кросс-валидации (cv) = {grid_search_calibrated_svc.best_params_['cv']}, метод калибровки: {grid_search_calibrated_svc.best_params_['method']}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_calibr.loc['SVC с калибровкой с аодобранными cv и method'] = [\n",
        "      round(logloss_svc_calibrated_upd, 4),\n",
        "      round(brier_svc_calibrated_upd, 4),\n",
        "      f'{grid_search_calibrated_svc.best_params_['cv']}',\n",
        "      f' {grid_search_calibrated_svc.best_params_['method']}'\n",
        "]\n",
        "\n",
        "display(df_metrics_calibr.style\n",
        "    .background_gradient(subset=['Logloss', 'Brier Score'], cmap='RdYlGn_r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Не получилось добиться лучшего качества калибровки, чем в исходном SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2dpbXgoP75X"
      },
      "source": [
        "##### __Бонус: Авторское решение__ (0.5 балла)\n",
        "\n",
        "Реализуйте свою функцию для калибровки вероятностей, используя любой из известных подходов. Кратко опишите ваш подход и продемонстрируйте результаты. Ключевые слова для вдохновения: `Platt`, `Isotonic`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8mtQgBJP75X"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaOVU4vJP75X"
      },
      "source": [
        "# Часть 2. Обработка категориальных переменных (4 балла + 1.5 бонус)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KQ9ywUEP75X"
      },
      "source": [
        "Как мы знаем, перекодировать категориальную переменную в список чисел (к примеру 1, 2, 3, ..., n) плохо, поскольку это бы задало на множестве ее значений некоторый порядок, не имеющий смысла.\n",
        "\n",
        "В этой части мы рассмотрим два основных способа обработки категориальных значений:\n",
        "- One-hot-кодирование\n",
        "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
        "\n",
        "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
        "$$\n",
        "b_i(x) = [f_j(x) = c_i]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPsScraBP75Y"
      },
      "source": [
        "#### __Подготовка данных__\n",
        "\n",
        "*(бесценный шаг)*\n",
        "\n",
        "Разберем датасет [покупок велосипедов](https://www.kaggle.com/datasets/heeraldedhia/bike-buyers/): даны признаки покупателя, требуется предсказать, купит ли он/она велосипед\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPuDzNoCo2nk"
      },
      "source": [
        "Замените пропуски в категориальных переменных на новую категорию (`'undefined'`)\n",
        "\n",
        "Разделите признаки на 2 таблицы: категориальные и числовые признаки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MTr7gi1PMqv",
        "outputId": "ac75b395-3705-4a43-f024-b793d0e48c80"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"heeraldedhia/bike-buyers\") +  \"/bike_buyers.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Прочитаем датасет\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape[0], df.ID.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Заменим пропуски категориальных переменных\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['Marital Status','Gender', 'Home Owner']] = df[['Marital Status','Gender', 'Home Owner']].fillna('undefined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Отделим X и y\n",
        "X = df.drop(['ID', 'Purchased Bike'], axis=1)\n",
        "y = df['Purchased Bike']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Разделим на категориальные признаки и числовые\n",
        "X_numerical = X[['Income', 'Children', 'Cars', 'Age']]\n",
        "X_categorical = X[['Marital Status', 'Gender', 'Education', 'Occupation', 'Home Owner', 'Commute Distance', 'Region']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch0M2v8Akirw"
      },
      "source": [
        "В начале поработаем только с категориальными признаками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y = np.where(y=='Yes', 1, 0) # для удобства сразу преобразовываю таргет в численный тип"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIYErZMnP75Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, test_size=0.25, random_state=777, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5LjHkuCP75Z"
      },
      "source": [
        "#### __Задание 3. OrdinalEncoder__  (0.5 балла)\n",
        "\n",
        "Закодируйте категориальные признаки с помощью `OrdinalEncoder`. Посчитайте качество (в этом задании будем работать c __`AUC-PR`__) при применении логистической регрессии. Замерьте время, потребовавшееся на обучение модели, с учетом кодирования признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdZT2tXXP75a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "ord_encoder = OrdinalEncoder()\n",
        "X_train1 = ord_encoder.fit_transform(X_train)\n",
        "X_test1 = ord_encoder.fit_transform(X_test)\n",
        "\n",
        "logreg_model = LogisticRegression(penalty='l2', verbose=2, random_state=777)\n",
        "logreg_model.fit(X_train1, y_train)\n",
        "\n",
        "y_test_pred_logreg = logreg_model.predict_proba(X_test1)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr = auc(recall_vals, precision_vals)\n",
        "\n",
        "time1 = time.time() - start\n",
        "print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr, 5)}')\n",
        "\n",
        "print(f'{time1} секунд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataframe для сравнения\n",
        "# моделей по метрикам\n",
        "df_models = pd.DataFrame(\n",
        "    columns=['auc_pr', 'time']   #, 'roc_auc_score', 'reg_const'\n",
        ")\n",
        "# добавление очередной строки с характеристиками метода\n",
        "df_models.loc['LogReg (Ordinal Encoding)'] = [\n",
        "      round(pr_auc_lr, 5),\n",
        "      round(time1, 5)\n",
        "    #  roc_auc_score(y_test, y_random),\n",
        "     # 0,\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "df_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Без подбора гиперпараметров и использования всех признаков качество не очень хорошее. Чуть лучше случайного классификатора"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScIo7NthP75a"
      },
      "source": [
        "#### __Задание 4. One-Hot Encoding__ (0.5 балла)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3sFuKAtLwOx"
      },
      "source": [
        "Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (в сравнении с тем, что было до кодирования). Измерьте время, потребовавшееся на кодирование категориальных признаков и обучение модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4PbjLIHP75a"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "X_train2 = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test2 = pd.get_dummies(X_test, drop_first=True)\n",
        "\n",
        "logreg_model = LogisticRegression(penalty='l2', verbose=2, random_state=777)\n",
        "logreg_model.fit(X_train2, y_train)\n",
        "\n",
        "y_test_pred_logreg = logreg_model.predict_proba(X_test2)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr2 = auc(recall_vals, precision_vals)\n",
        "\n",
        "#print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr2, 5)}')\n",
        "\n",
        "time2 = round(time.time() - start, 5)\n",
        "print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr, 5)}')\n",
        "print(f'{round(time2, 5)} секунд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_models.loc['LogReg (OHE)'] = [\n",
        "      round(pr_auc_lr2, 5),\n",
        "      time2\n",
        "    #  roc_auc_score(y_test, y_random),\n",
        "     # 0,\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "df_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p-qOs6lP75b"
      },
      "source": [
        "Как можно заметить, one-hot-кодирование может сильно увеличивать количество признаков. Это сказывается на объеме необходимой памяти, особенно, если некоторый признак имеет большое количество значений.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1q3k3yaLF8Y"
      },
      "source": [
        "#### __Задание 5. Mean-target Encoding__ (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tanu5Hm5Lr7R"
      },
      "source": [
        "> Проблемы разрастания числа признаков можно избежать в другом способе кодирования категориальных признаков — mean-target encoding (для простоты будем называть это __счётчиками__). Сравним эффективность методов в рамках нашей маркетинговой задачи.\n",
        "\n",
        "> Основная идея в том, что важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
        "\n",
        "$$\n",
        "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}\n",
        "$$\n",
        "\n",
        "Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше, без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве.\n",
        "\n",
        "Сравните время обучения с предыдущими экспериментами (с учетом кодирования признаков)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9MNSGWrgz5-"
      },
      "outputs": [],
      "source": [
        "# здесь для удобства добавляю таргет как столбец\n",
        "Xtc = X_train.copy()\n",
        "Xtc['buy'] = y_train\n",
        "Xtc.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я написал 2 реализации функции, выполняющей Mean-target Encoding. **Первая работает за O(n^2)**, при большом датасете это долго.\\\n",
        "**Вторая работает за O(n)**    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Первая реализация**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_target_encoding(cat_features_df, target): # на вход подается датасет с категориальными фичами и таргет\n",
        "    for col in cat_features_df.loc[:, cat_features_df.columns != target].columns:\n",
        "        for category in cat_features_df[col].unique():\n",
        "            cat_features_df.loc[cat_features_df[col] == category, col] = cat_features_df[cat_features_df[col] == category][target].mean()\n",
        "\n",
        "    return cat_features_df      \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_target_encoding(Xtc, 'buy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xtc.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Вторая реализация (быстрее)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xtc2 = X_train.copy()\n",
        "Xtc2['buy'] = y_train\n",
        "Xtc2.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_target_encoding2(cat_features_df, target): # на вход подается датасет с категориальными фичами и таргет\n",
        "    for col in cat_features_df.loc[:, cat_features_df.columns != target].columns:\n",
        "        cat_features_df[col] = cat_features_df.groupby(col)[target].transform('mean')\n",
        "\n",
        "    return cat_features_df      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_target_encoding2(Xtc2, 'buy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xtc2.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# фкнкция для применения маппинга на тестовую выборку\n",
        "\n",
        "def apply_encoding_to_test(X_test, X_train_encoded, target_col):\n",
        "    X_test_encoded = X_test.copy()\n",
        "    for col in X_test.columns:\n",
        "        # Беру маппинг из тренировочных данных\n",
        "        mapping = X_train_encoded.groupby(col)[target_col].mean()\n",
        "        X_test_encoded[col] = X_test[col].map(mapping)\n",
        "    return X_test_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Кодирование + обучение + тест**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, test_size=0.25, random_state=777, stratify=y)\n",
        "\n",
        "Xtrc = X_train.copy()\n",
        "Xtrc['buy'] = y_train\n",
        "\n",
        "Xtec = X_test.copy()\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "Xtrc_encoded = mean_target_encoding2(Xtrc, 'buy')\n",
        "\n",
        "Xtec_encoded = apply_encoding_to_test(Xtec, Xtrc_encoded, 'buy')  # применяю к тестовой выборке\n",
        "Xtec_encoded = Xtec_encoded.fillna(Xtrc_encoded['buy'].mean())\n",
        "\n",
        "Xtrc_final = Xtrc_encoded.drop('buy', axis=1) # удаляю таргет из трейн выборки перед обучением\n",
        "\n",
        "\n",
        "\n",
        "logreg_model = LogisticRegression(penalty='l2', verbose=2, random_state=777)\n",
        "logreg_model.fit(Xtrc_final, y_train)\n",
        "\n",
        "y_test_pred_logreg = logreg_model.predict_proba(Xtec_encoded)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr3 = auc(recall_vals, precision_vals)\n",
        "\n",
        "time3 = round(time.time() - start, 5)\n",
        "print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr3, 5)}')\n",
        "\n",
        "print(f'{time3} секунд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_models.loc['LogReg (Mean-target-encoding)'] = [\n",
        "      round(pr_auc_lr3, 5),\n",
        "      time3\n",
        " \n",
        "]\n",
        "\n",
        "df_models\n",
        "\n",
        "display(df_models.style\n",
        "    .background_gradient(subset=['auc_pr'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Mean-target-encoding оказался самым эффективным способом**, при этом он работает в ~5 раз дольше, что для больших данных может быть критично"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABXherJ3LGBj"
      },
      "source": [
        "##### __Бонус: Эффективная реализация (1 балл)__\n",
        "\n",
        "Здесь и далее реализуйте вычисление счетчиков с помощью трансформера (наследуйтесь от классов `BaseEstimator, TransformerMixin` из `sklearn.base`). Обратите внимание, что все вычисления должны быть векторизованными, трансформер не должен модифицировать передаваемую ему выборку inplace, а все необходимые статистики нужно считать только по обучающей выборке в методе `fit`. Ваш трансформер должен принимать при инициализации список из категориальных признаков и изменять только их."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk8D4dDuP75b"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH-JPoINqJ62"
      },
      "source": [
        "_______\n",
        "\n",
        "__Методы борьбы с переобучением счетчиков__\n",
        "\n",
        "\n",
        "Отметим, что mean-target encoding признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к __переобучению__, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его __целевая метка не использовалась__.\n",
        "\n",
        "Это можно делать следующими способами:\n",
        "1. Вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени).\n",
        "2. Вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации).\n",
        "3. Внесение некоторого шума в посчитанные признаки.\n",
        "\n",
        "#### __Задание 6. Пошумим__  (0.5 балла)\n",
        "\n",
        "Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям.  При этом постарайтесь найти баланс между борьбой с переобучением и сохранением полезности признаков. Снова обучите логистическую регрессию, оцените качество."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для начала я хочу посмотреть на разницу AUC-ROC на трейн и тест выборке прошлой модели, чтоб понять, **насколько сильное переобучение сейчас**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xtrc_encoded_fs = Xtrc_encoded.drop(columns=['buy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr3, 5)}')\n",
        "\n",
        "y_train_pred_logreg = logreg_model.predict_proba(Xtrc_encoded_fs)[:,1]    # предсказываю для трейна\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_train, y_train_pred_logreg)\n",
        "pr_auc_lr3_train = auc(recall_vals, precision_vals)\n",
        "\n",
        "print(f'На обучающей выборке AUC-PR = {round(pr_auc_lr3_train, 5)}')\n",
        "\n",
        "print(f'Абсолютная разница AUC-PR = {round(pr_auc_lr3_train, 5) - round(pr_auc_lr3, 5)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Нетипичная картина, на тестовой выборке качество лучше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Я добавляю шум из нормального распределения  с разными дисперсиями**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Функция MTE с шумом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_target_encoding_with_noise(cat_features_df, target, noise_level=0.05, random_state=777):\n",
        "    \n",
        "    np.random.seed(random_state)\n",
        "    df_encoded = cat_features_df.copy()\n",
        "    \n",
        "    for col in cat_features_df.loc[:, cat_features_df.columns != target].columns:\n",
        "        means = cat_features_df.groupby(col)[target].mean()\n",
        "        \n",
        "        # Применяю кодировку\n",
        "        df_encoded[col] = cat_features_df[col].map(means)\n",
        "        \n",
        "        # Добавляю шум к обучающим данным\n",
        "        # Шум из нормального распределения с std = noise_level * std таргета\n",
        "        target_std = cat_features_df[target].std()\n",
        "        noise = np.random.normal(0, noise_level * target_std, size=len(df_encoded))\n",
        "        df_encoded[col] += noise\n",
        "    \n",
        "    return df_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Обучаю модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Пробую разные уровни шума"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for noise_level in tqdm([0.01, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2, 0.3]):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, test_size=0.25, random_state=777, stratify=y)\n",
        "\n",
        "    Xtrc = X_train.copy()\n",
        "    Xtrc['buy'] = y_train\n",
        "    Xtec = X_test.copy()\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    Xtrc_encoded = mean_target_encoding_with_noise(Xtrc, 'buy', noise_level=noise_level, random_state=777)\n",
        "\n",
        "    # К тестовой выборке применяю обычную кодировку без шума\n",
        "    Xtec_encoded = apply_encoding_to_test(Xtec, Xtrc_encoded, 'buy')\n",
        "    Xtec_encoded = Xtec_encoded.fillna(Xtrc_encoded['buy'].mean())\n",
        "\n",
        "    Xtrc_final = Xtrc_encoded.drop('buy', axis=1)\n",
        "\n",
        "    logreg_model = LogisticRegression(penalty='l2', verbose=2, random_state=777)\n",
        "    logreg_model.fit(Xtrc_final, y_train)\n",
        "\n",
        "    y_test_pred_logreg = logreg_model.predict_proba(Xtec_encoded)[:,1]\n",
        "\n",
        "    precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "    pr_auc_lr4 = auc(recall_vals, precision_vals)\n",
        "\n",
        "    time4 = round(time.time() - start, 5)\n",
        "    print(f'Уровень шума = {noise_level}')\n",
        "    print(f'На тестовой выборке AUC-PR = {round(pr_auc_lr4, 5)}')\n",
        "    print(f'{time4} секунд')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Поднять ROC - AUC больше 0.74 не вышло, но мы сохранили результат, **это уже хорошо** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выберем из моделей, дающих roc-auc = 0.74 модель с **наименьшей разницей между трейн и тест выборкой**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for noise_level in tqdm([0.05, 0.15, 0.3]):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, test_size=0.25, random_state=777, stratify=y)\n",
        "\n",
        "    Xtrc = X_train.copy()\n",
        "    Xtrc['buy'] = y_train\n",
        "    Xtec = X_test.copy()\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    Xtrc_encoded = mean_target_encoding_with_noise(Xtrc, 'buy', noise_level=noise_level, random_state=777)\n",
        "\n",
        "    # К тестовой выборке применяю обычную кодировку без шума\n",
        "    Xtec_encoded = apply_encoding_to_test(Xtec, Xtrc_encoded, 'buy')\n",
        "    Xtec_encoded = Xtec_encoded.fillna(Xtrc_encoded['buy'].mean())\n",
        "\n",
        "    Xtrc_final = Xtrc_encoded.drop('buy', axis=1)\n",
        "\n",
        "    logreg_model = LogisticRegression(penalty='l2', verbose=2, random_state=777)\n",
        "    logreg_model.fit(Xtrc_final, y_train)\n",
        "\n",
        "    y_test_pred_logreg = logreg_model.predict_proba(Xtec_encoded)[:,1]\n",
        "\n",
        "    precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "    pr_auc_lr4 = auc(recall_vals, precision_vals)\n",
        "\n",
        "    \n",
        "    y_train_pred_logreg = logreg_model.predict_proba(Xtrc_final)[:,1]\n",
        "\n",
        "    precision_vals_tr, recall_vals_tr, thresholds_tr = precision_recall_curve(y_train, y_train_pred_logreg)\n",
        "    pr_auc_lr4_train = auc(recall_vals_tr, precision_vals_tr)\n",
        "\n",
        "    time4 = round(time.time() - start, 5)\n",
        "    print(f'Уровень шума = {noise_level}')\n",
        "    print(f'Разгица ROC-AUC между трейн и тест выборкой = {round(pr_auc_lr4_train - pr_auc_lr4, 5)}')\n",
        "    print(f'{time4} секунд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Наименьшая разница при уровне шума = **0.05**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOxwE8rGLSzH"
      },
      "source": [
        "**Вопрос:** Сделайте выводы. Помогло ли добавление шума? Почему?\n",
        "\n",
        "**Ответ:** Добавление шума не помогло. Я связываю это с достаточно большим кол-вом данных, плюс, видимо, переобучения не было изначально"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GtUtPCjP75c"
      },
      "source": [
        "##### __Бонус: другой подход__ (0.5 балла)\n",
        "\n",
        "Посчитайте корректные счётчики первым или вторым способов из описанных выше (не забудьте добавить и шум).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjqsSTd6P75c"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMe2b5i6P75d"
      },
      "source": [
        "#### __Задание 7. Сглаживание счетчиков__  (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gnmTaJqP75d"
      },
      "source": [
        "> Теперь ответим на следующий вопрос: что будет, если некоторая категория встречается в выборке всего несколько раз? По этой причине производится сглаживание счётчиков. Например, на практике хорошие результаты показывает использование сглаживания средним по всей выборке:\n",
        "$$\n",
        "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1] + C \\times \\text{global_mean}}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)] + C}\n",
        "$$\n",
        "где $\\text{global_mean}$ — доля объектов положительного класса в выборке, $C$ — параметр, определяющий степень сглаживания (можно использовать 10 или подобрать для каждого признака свой). Идея в том, что мы \"разбавляем\" среднее значение по категории глобальным средним значением. И тем меньше, чем большее количество объектов этой категории встречается в выборке.\n",
        "\n",
        "> Вместо среднего значения целевой переменной для сглаживания можно использовать любое другое значение от 0 до 1 (этот параметр иногда называют $prior$). Можно сделать несколько признаков с разными значениями параметра. На практике в задачах бинарной классификации полезными бывают даже отрицательные значения!\n",
        "\n",
        "Добавьте сглаживание, описанное выше и повторите эксперименты. Подберите $C$, чтобы качество было лучше, чем при использовании One-Hot-Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xRMlYQlP75d"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TksKMbr_P75d"
      },
      "source": [
        "#### **Задание 8. Числовые или категориальные?**  (0.5 балла)\n",
        "\n",
        "Теперь добавим числовые признаки к счётчикам (тем, которые дали наибольший прирост качества).\n",
        "\n",
        "\n",
        "Проверьте их на наличие выбросов и заполните пропуски средним или медианой, подумайте, что лучше в условиях наших данных\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDA числовых признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.histplot(X_numerical['Income'], bins=30, kde=True, color='#4C72B0', edgecolor='red')\n",
        "\n",
        "plt.axvline(X_numerical['Income'].median(), color='yellow', linestyle='--', linewidth=2, label=f'Медиана: {X_numerical['Income'].median():.1f}')\n",
        "plt.axvline(X_numerical['Income'].mean(), color='red', linestyle='--', linewidth=2, label=f'Среднее: {X_numerical['Income'].mean():.1f}')\n",
        "\n",
        "plt.xlabel('Доход')\n",
        "plt.ylabel('Частота')\n",
        "plt.title('Гистограмма распределения по доходу')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(10, 2))\n",
        "boxplot = sns.boxplot(\n",
        "    data=X_numerical['Income'], \n",
        "    orient=\"h\",\n",
        "    width=0.6,\n",
        "    color=\"#E84393\",\n",
        "    linewidth=2,\n",
        "    flierprops=dict(\n",
        "        markerfacecolor='#DD8452',\n",
        "        marker='D', \n",
        "        markersize=6\n",
        "    ),\n",
        "    boxprops=dict(alpha=0.8)\n",
        ")\n",
        "plt.title(\"Распределение доходов людей\", pad=20, fontsize=14)\n",
        "plt.xlabel(\"Доход\", fontsize=12)\n",
        "#plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical[X_numerical['Income'] > 140000].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Выбросов немного, оставлю их."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical['Income'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выбросов не очень много. Я предполагаю, что распределение логнормальное. Проверим это:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.histplot(np.log1p(X_numerical['Income']), bins=30, kde=True, color='#4C72B0', edgecolor='red')\n",
        "plt.xlabel('Доход')\n",
        "plt.ylabel('Частота')\n",
        "plt.title('Гистограмма распределения по доходу')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Не уверен, что логнормальное"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Заполняю пропуски в доходе медианой, их немного\n",
        "\n",
        "X_numerical['Income'].fillna(X_numerical['Income'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.histplot(X_numerical['Age'], bins=30, kde=True, color='orange', edgecolor='red')\n",
        "\n",
        "plt.axvline(X_numerical['Age'].median(), color='yellow', linestyle='--', linewidth=2, label=f'Медиана: {X_numerical['Age'].median():.1f}')\n",
        "plt.axvline(X_numerical['Age'].mean(), color='red', linestyle='--', linewidth=2, label=f'Среднее: {X_numerical['Age'].mean():.1f}')\n",
        "\n",
        "plt.xlabel('Возраст')\n",
        "plt.ylabel('Частота')\n",
        "plt.title('Гистограмма распределения по возрасту')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Судя по гистограмме, есть выбросы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(10, 2))\n",
        "boxplot = sns.boxplot(\n",
        "    data=X_numerical['Age'], \n",
        "    orient=\"h\",\n",
        "    width=0.6,\n",
        "    color=\"orange\",\n",
        "    linewidth=2,\n",
        "    flierprops=dict(\n",
        "        markerfacecolor='#DD8452',\n",
        "        marker='D', \n",
        "        markersize=6\n",
        "    ),\n",
        "    boxprops=dict(alpha=0.8)\n",
        ")\n",
        "plt.title(\"Распределение возраста людей\", pad=20, fontsize=14)\n",
        "plt.xlabel(\"Возраст\", fontsize=12)\n",
        "#plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical[X_numerical['Age'] > 75].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выбросов по возрасту почти нет. Оставляем как есть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# пропуски заменяю медианой\n",
        "\n",
        "X_numerical['Age'].fillna(X_numerical['Age'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "ax = sns.countplot(\n",
        "    data=X_numerical,\n",
        "    x='Children',\n",
        "\n",
        "    edgecolor='black'\n",
        ")\n",
        "\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%d', label_type='edge', padding=3)\n",
        "\n",
        "plt.title('Разбивка выборки по количеству детей', fontsize=14, pad=10)\n",
        "plt.xlabel('Количество детей', fontsize=13)\n",
        "plt.ylabel('Частота', fontsize=12)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical['Children'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Заменим пропуски медианой - 2 ребенка, как ине кажется, это достаточно правдоподобно\n",
        "\n",
        "X_numerical['Children'].fillna(X_numerical['Children'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "ax = sns.countplot(\n",
        "    data=X_numerical,\n",
        "    x='Cars',\n",
        "    edgecolor='black'\n",
        ")\n",
        "\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%d', label_type='edge', padding=3)\n",
        "\n",
        "plt.title('Разбивка выборки по количеству машин', fontsize=14, pad=10)\n",
        "plt.xlabel('Количество машин', fontsize=13)\n",
        "plt.ylabel('Частота', fontsize=12)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_numerical['Cars'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Заменим пропуски на медиану - 1 машину\n",
        "\n",
        "X_numerical['Cars'].fillna(X_numerical['Cars'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfqXdaqblnZo"
      },
      "source": [
        " Сейчас для числовых признаков мы ищем линейную зависимость, что в общем случае  может быть неверной гипотезой. Тем не менее, у этих признаков есть довольно много уникальных значений (сколько?), поэтому применять к ним one-hot кодирование может оказаться излишним. Попробуйте закодировать эти признаки с помощью счетчиков. Стало ли лучше?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p_jGTg-h3MG"
      },
      "outputs": [],
      "source": [
        "for ft in X_numerical.columns:\n",
        "    print(f'У признака {ft} {X_numerical[ft].nunique()} уникальных значений')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X8 = pd.merge(X_numerical, X_categorical, left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X8.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Кодирую с помощью счетчиков:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X8, y, test_size=0.25, random_state=777, stratify=y)\n",
        "\n",
        "Xtrc = X_train.copy()\n",
        "Xtrc['buy'] = y_train\n",
        "\n",
        "Xtec = X_test.copy()\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "Xtrc_encoded = mean_target_encoding2(Xtrc, 'buy')\n",
        "\n",
        "Xtec_encoded = apply_encoding_to_test(Xtec, Xtrc_encoded, 'buy')  # применяю к тестовой выборке\n",
        "Xtec_encoded = Xtec_encoded.fillna(Xtrc_encoded['buy'].mean())\n",
        "\n",
        "Xtrc_final = Xtrc_encoded.drop('buy', axis=1) # удаляю таргет из трейн выборки перед обучением\n",
        "\n",
        "\n",
        "\n",
        "logreg_model = LogisticRegression(penalty='l2', verbose=2, random_state=777)\n",
        "logreg_model.fit(Xtrc_final, y_train)\n",
        "\n",
        "y_test_pred_logreg = logreg_model.predict_proba(Xtec_encoded)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr8 = auc(recall_vals, precision_vals)\n",
        "\n",
        "time8 = round(time.time() - start, 5)\n",
        "\n",
        "print(f'На тестовой выборке AUC-ROC = {round(pr_auc_lr8, 5)}')\n",
        "\n",
        "print(f'{time8} секунд')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Лучше почему-то не стало. Пока не можем пробить ROC-AUC больше 0.74**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia0qk__0iNCS"
      },
      "source": [
        "> __Замечание.__ Усложнение методов вычисления счётчиков не делают результаты модели гарантированно лучше. Особенно с учётом того, что логистическая регрессия не такая сложная модель, чтобы переобучаться. Поэтому вы необязательно должны были получать на каждом шаге всё лучшие и лучшие результаты (но необходимые результаты у вас должны были получиться)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mwXyUnOP75e"
      },
      "source": [
        "\n",
        "\n",
        "Как мы могли пронаблюдать, счётчики являются конкурентной альтернативой one-hot-кодированию. Опишите, какие плюсы и минусы использования счётчиков по сравнению с one-hot-кодированием вы заметили.\n",
        "\n",
        "__Ответ:__ \n",
        "\n",
        "**Плюсы MTE в сравнении с OHE**: не увеличвает размерность, сохраняет инф-ю о таргете, лучше работает с редкими категориями, можно проще интерпретировать\n",
        "\n",
        "**Минусы MTE в сравнении с OHE**: утечка таргета в признаки, высокий риск переобучения, сложно обработать новые категории в тесте"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oU4I7HjP75f"
      },
      "source": [
        "# Часть 3. Отбор признаков (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsmcHDoZNu5l"
      },
      "source": [
        "Загрузим данные [UCI Adult Dataset](https://archive.ics.uci.edu/ml/datasets/Adult). Этот набор данных содержит информацию о годовых доходах отдельных людей. В качестве признакового описания используется различная информация о человеке (образование, профессия, брачный статус и т.д.). Целевая переменная является бинарной: больше ли годовой доход 50K долларов или нет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk7jX8EsNrz2"
      },
      "outputs": [],
      "source": [
        "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVqw4RQ5iXRC"
      },
      "outputs": [],
      "source": [
        "columns = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
        "    'income'\n",
        "]\n",
        "\n",
        "df = pd.read_csv('adult.data', header=None, names=columns)\n",
        "df['income'] = (df['income'] != \" <=50K\").astype('int32')\n",
        "df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['fnlwgt'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я прочитал, что **fnlwgt отражает количество людей со схожими характеристиками**. Поэтому при прогнозировании использовать его я не буду."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['occupation'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKb6BsQMP75f"
      },
      "source": [
        "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом их расчёт занимает время) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGqys4ZpiXjr"
      },
      "source": [
        "Разделите выборку на обучающую и тестовую в соотношении 3:1. Зафиксируйте `random_state=777`, также используйте `stratify=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2TT35c_iYc-"
      },
      "outputs": [],
      "source": [
        "y = df['income']\n",
        "X = df.drop(columns=['fnlwgt', 'income', 'education'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uAlw2X-P75f"
      },
      "source": [
        "Давайте закодируем все категориальные признаки с помощью One-hot Encoding. Сколько новых признаков мы получим?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**education-num** - это числовое представление признака education. Я оставлю его, и удалю educztion, так как education-num сохраняет порядок категорий, что для признака уровень образования и наших классификаторов (SVM, Лог регрессия) будет полезно (удаляю education выше)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train['workclass'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train['native-country'].value_counts()[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Числовые признаки я решил обработать Scalerом**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILg-JGugP75f"
      },
      "outputs": [],
      "source": [
        "# подготовка признаков\n",
        "\n",
        "categorical_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']  # категориальные признаки\n",
        "numeric_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'] # числовые признаки\n",
        "\n",
        "preprocessor1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "preprocessor1.fit(X_train)\n",
        "X_train_transformed = preprocessor1.transform(X_train)\n",
        "X_test_transformed = preprocessor1.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Исходная размерность X_train: {X_train.shape}\")\n",
        "print(f\"Размерность после OHE и Scaling: {X_train_transformed.shape}\")\n",
        "print(f\"Количество новых признаков: {X_train_transformed.shape[1] - X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq-XZwf3P75g"
      },
      "source": [
        "В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — `AUC-PR`. Обучите модель и посчитайте качество на тестовой выборке. Давайте запомним полученное значение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# подбираю оптимальное C\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LogReg = LogisticRegression(penalty='l2')\n",
        "grid_search_lr1 = GridSearchCV(LogReg, param_grid, cv = 5, verbose=2, scoring='average_precision') # 5 фолдов для кросс-валидации\n",
        "grid_search_lr1.fit(X_train_transformed, y_train)\n",
        "\n",
        "\n",
        "y_test_pred_logreg = grid_search_lr1.predict_proba(X_test_transformed)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr9 = auc(recall_vals, precision_vals)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr1.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr1.best_score_)\n",
        "print(\"Test Score:\", pr_auc_lr9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3 = pd.DataFrame(\n",
        "    columns=['auc_pr_valid', 'auc_pr_test', 'reg_const']\n",
        ")\n",
        "#precision, recall, _ = precision_recall_curve(y_test, y_random)\n",
        "# добавление очередной строки с характеристиками метода\n",
        "df_metrics_part3.loc['LogReg'] = [\n",
        "      round(grid_search_lr1.best_score_, 4),\n",
        "      round(pr_auc_lr9, 4),\n",
        "      grid_search_lr1.best_params_['C']\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "df_metrics_part3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Качество на тесте неплохое для такой простой модели!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrbIEFGUIQ6I"
      },
      "source": [
        "Допустим, мы хотим оставить только 40 лучших признаков.\n",
        "\n",
        "Заметим, что нельзя оценивать качество по тестовой выборке, иначе мы можем переобучиться, как, например, при настройке гиперпараметров. Разделите обучающую выборку на 2 части, одну из которых, используйте для валидации. Исходную тестовую выборку стоит использовать только для финальной оценки качества после процедуры фильтрации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я прочитал, что для отбора признаков очень хорош **случайный лес, так как в нем встроен отбор признаков, + он улавливает сложные взаимодействия между признаками**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuHUvh0UwsxZ"
      },
      "outputs": [],
      "source": [
        "# готовлю данные\n",
        "\n",
        "\n",
        "y = df['income']\n",
        "X = df.drop(columns=['fnlwgt', 'income', 'education'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.35, random_state=777) # я решил оставить 35% на валидацию\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Реализовываю пайплайн\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('feature_selector', SelectFromModel(\n",
        "        RandomForestClassifier(n_estimators=100, random_state=777, n_jobs=-1),\n",
        "        max_features=40\n",
        "    )),\n",
        "    ('classifier', LogisticRegression(penalty='l2', random_state=777, max_iter=1000))\n",
        "])\n",
        "\n",
        "# сетка гиперпараметров\n",
        "param_grid = {\n",
        "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__solver': ['liblinear', 'lbfgs'] # решил добавить еще и подбор метода оптимизации\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "grid_search_lr = GridSearchCV(\n",
        "    pipeline, \n",
        "    param_grid, \n",
        "    cv=5, \n",
        "    verbose=2, \n",
        "    scoring='average_precision',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search_lr.fit(X_train, y_train) \n",
        "\n",
        "\n",
        "y_test_pred_logreg = grid_search_lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg)\n",
        "pr_auc_lr = auc(recall_vals, precision_vals)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr.best_score_)\n",
        "print(\"Test PR-AUC Score:\", round(pr_auc_lr, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Качество на тестовой выборке **чуть упало**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3.loc['LogReg with 40 best features (selected by RandomForest)'] = [\n",
        "      round(grid_search_lr.best_score_, 4),\n",
        "      round(pr_auc_lr, 4),\n",
        "      100\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "df_metrics_part3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация важности признаков (в построении мне помог deepseek)\n",
        "\n",
        "best_pipeline = grid_search_lr.best_estimator_\n",
        "feature_selector = best_pipeline.named_steps['feature_selector']\n",
        "preprocessor = best_pipeline.named_steps['preprocessor']\n",
        "\n",
        "# имена признаков\n",
        "all_feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "selected_mask = feature_selector.get_support()\n",
        "selected_feature_names = all_feature_names[selected_mask]\n",
        "\n",
        "# важность признаков из RF\n",
        "rf_model = feature_selector.estimator_\n",
        "feature_importance = rf_model.feature_importances_\n",
        "\n",
        "selected_importance = feature_importance[selected_mask]\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': selected_feature_names,\n",
        "    'importance': selected_importance\n",
        "}).sort_values('importance', ascending=True)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.barh(importance_df['feature'], importance_df['importance'])\n",
        "plt.xlabel('Важность признака')\n",
        "plt.title('Топ самых важных признаков (Random Forest)', fontsize=14, pad=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как я и предполагал, в топе важных признаков - **возраст, уровень образования**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hymygH5YwveY"
      },
      "source": [
        "Попробуем сделать это следующими способами:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD7jIiDeP75g"
      },
      "source": [
        "#### __Задание 9. Встроенные методы (0.5 балла)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf2T9xtUP75g"
      },
      "source": [
        "Начнём с отбора признаков с помощью модели. У разных алгоритмов есть разные встроенные способы оценки вклада признаков в предсказание. Как известно, у линейной модели за это отвечают веса, а значит, их модуль можно интерпретировать как важность. Такой метод отбора называются встроенным или embedded method, так как он заложен в особенности модели.\n",
        "\n",
        "Оставьте 40 признаков с наибольшим модулем соответствующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_logreg = grid_search_lr1.best_estimator_\n",
        "\n",
        "coefficients = best_logreg.coef_[0]\n",
        "\n",
        "\n",
        "feature_names = preprocessor1.get_feature_names_out()\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'coefficient': coefficients,\n",
        "    'abs_coefficient': np.abs(coefficients)\n",
        "}).sort_values('abs_coefficient', ascending=False)\n",
        "coef_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coef_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_transformed.shape, X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# обучаю модель на 40 лучших признаках\n",
        "\n",
        "top_40_features = coef_df.head(40)['feature'].values\n",
        "\n",
        "\n",
        "feature_mask = [name in top_40_features for name in feature_names]\n",
        "\n",
        "X_train_top40 = X_train_transformed[:, feature_mask]\n",
        "X_test_top40 = X_test_transformed[:, feature_mask]\n",
        "#y_train_top40 = y_train[feature_mask]\n",
        "\n",
        "\n",
        "logreg_top40 = LogisticRegression(penalty='l2', random_state=777, max_iter=1000)\n",
        "grid_search_top40 = GridSearchCV(\n",
        "    logreg_top40, \n",
        "    param_grid, \n",
        "    cv=5, \n",
        "    verbose=2, \n",
        "    scoring='average_precision'\n",
        ")\n",
        "grid_search_top40.fit(X_train_top40, y_train)\n",
        "\n",
        "# оцениваю на тестовой выборке\n",
        "y_test_pred_top40 = grid_search_top40.predict_proba(X_test_top40)[:, 1]\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_top40)\n",
        "pr_auc_top40 = auc(recall_vals, precision_vals)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_top40.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_top40.best_score_)\n",
        "print(\"Test PR-AUC Score:\", pr_auc_top40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3.loc['LogReg with 40 best features (selected by weights)'] = [\n",
        "      round(grid_search_top40.best_score_, 4),\n",
        "      round(pr_auc_top40, 4),\n",
        "      100000\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "\n",
        "display(df_metrics_part3.style\n",
        "    .background_gradient(subset=['auc_pr_test'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# здесь чуть поломалось при повторном запуске, но выводы ниже верные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Изменилось ли качество? Как?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Качество чуть улучшилось при отборе по весам!**\\\n",
        "При этом отбор с помощью RandomForest показал худшие результаты на тесте"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5y5hVyYP75h"
      },
      "source": [
        "Подумаем, что мы не учли. Мы действовали в предположении, что признаки вносят вклад равномерно, и не учитывали их масштаб. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отмасштабируем признаки одним из способов, а только потом будем удалять признаки.\n",
        "\n",
        "Помните, что не все способы одинаково хороши, особенно в условиях наличия выбросов\n",
        "\n",
        "Что получилось?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXytEuBgP75h"
      },
      "source": [
        "Я **отмасштабировал в самом начале**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLZJRpxjP75h"
      },
      "source": [
        "Вопрос на засыпку: one-hot кодирование возвращает нам единичные признаки-индикаторы. Попробуйте также отскалировать их, как и обычные числовые, и снова выбрать 40 главных по вкладу признаков. Изменился ли их список? Изменится ли качество?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['income']\n",
        "X = df.drop(columns=['fnlwgt', 'income', 'education'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_pipeline = Pipeline([\n",
        "    ('ohe', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "new_pipeline.fit(X_train)\n",
        "X_train_scaled = new_pipeline.transform(X_train)\n",
        "X_valid_scaled = new_pipeline.transform(X_valid)\n",
        "X_test_scaled = new_pipeline.transform(X_test)\n",
        "\n",
        "\n",
        "feature_names = new_pipeline.named_steps['ohe'].get_feature_names_out()\n",
        "print(\"Имена признаков после OHE + StandardScaler:\")\n",
        "print(feature_names[:40])  # первые 40 признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_transformed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(feature_mask[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'lbfgs'] # решил добавить еще и подбор метода оптимизации\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_40_features1 = feature_names[:40]\n",
        "feature_mask = [name in top_40_features1 for name in feature_names]\n",
        "\n",
        "X_train_top40 = X_train_scaled[:, feature_mask]\n",
        "X_test_top40 = X_test_scaled[:, feature_mask]\n",
        "\n",
        "\n",
        "logreg_top40_ohe_ss = LogisticRegression(penalty='l2', random_state=777, max_iter=1000)\n",
        "grid_search_top40_ohe_ss = GridSearchCV(\n",
        "    logreg_top40_ohe_ss, \n",
        "    param_grid, \n",
        "    cv=5, \n",
        "    verbose=2, \n",
        "    scoring='average_precision'\n",
        ")\n",
        "grid_search_top40_ohe_ss.fit(X_train_top40, y_train)\n",
        "\n",
        "# оцениваю на тестовой выборке\n",
        "y_test_pred_top40 = grid_search_top40_ohe_ss.predict_proba(X_test_top40)[:, 1]\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_top40)\n",
        "pr_auc_top40 = auc(recall_vals, precision_vals)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_top40_ohe_ss.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_top40_ohe_ss.best_score_)\n",
        "print(\"Test PR-AUC Score:\", pr_auc_top40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Качество очень упало. Это связано с тем, что **не стоит использовать методы обработки числовых признаков для категориальных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nK78Ag2P75i"
      },
      "source": [
        "#### __Задание 10. Методы фильтрации (0.5 балла)__\n",
        "\n",
        "\n",
        "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods.\n",
        "\n",
        "Одна из самых простых функция - корреляция между признаком и целевой переменной. Подумайте, какая взаимосвязь между корреляцией и предсказательной способностью модели, и как бы вы использовали информацию о корреляции для отбора признаков\n",
        "\n",
        "**Ответ:** чем выше модуль корреляции между признаком и таргетом - **тем сильнее линейная взаимосвязь между ними.** Логично предположить, что чем выше корреляция таргета и признаков, тем сильнее предсказательная способность модели. Я бы брал признаки с наибольшей по модулю корреляцией с таргетом.\n",
        "\n",
        "Посчитайте корреляцию каждого признака с таргетом и отфильтруйте 40 признаков исходя из того, что вы описали, после чего замерьте качество и время отбора\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['income']\n",
        "X = df.drop(columns=['fnlwgt', 'income', 'education'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# подготовка признаков\n",
        "\n",
        "categorical_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']  # категориальные признаки\n",
        "numeric_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'] # числовые признаки\n",
        "\n",
        "preprocessor_new = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "preprocessor_new.fit(X_train)\n",
        "X_train_transformed = preprocessor_new.transform(X_train)\n",
        "X_test_transformed = preprocessor_new.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# сопоставляю имена со столбцами X_train_transformed\n",
        "\n",
        "cat_encoder = preprocessor_new.named_transformers_['cat']\n",
        "cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
        "\n",
        "all_feature_names = numeric_features + list(cat_feature_names)\n",
        "\n",
        "print(f\"Всего признаков: {len(all_feature_names)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_df = pd.DataFrame(X_train_transformed, columns=all_feature_names)\n",
        "X_test_df = pd.DataFrame(X_test_transformed, columns=all_feature_names)\n",
        "\n",
        "X_train_df['target'] = y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# считаю корреляции\n",
        "correlations = X_train_df.corr()['target'].sort_values(ascending=False)\n",
        "\n",
        "correlations.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# беру модули\n",
        "\n",
        "correlations_abs = np.abs(correlations)\n",
        "correlations_abs.sort_values(ascending=False).head(41) # беру 40 лучших"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_40_corr  = correlations_abs.sort_values(ascending=False).head(41).index.tolist()\n",
        "top_40_corr = [el for el in top_40_corr if el != 'target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# обучаю только на них\n",
        "\n",
        "X_train_corr = X_train_df.drop(columns='target', axis=1)\n",
        "X_test_corr = X_test_df.copy()\n",
        "\n",
        "X_train_corr = X_train_corr[top_40_corr]\n",
        "X_test_corr = X_test_corr[top_40_corr]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LogReg_top40corr = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "grid_search_lr0 = GridSearchCV(LogReg_top40corr, param_grid, cv = 5, verbose=2, scoring='average_precision') # 5 фолдов для кросс-валидации\n",
        "grid_search_lr0.fit(X_train_corr, y_train)\n",
        "\n",
        "\n",
        "y_test_pred_logreg0 = grid_search_lr0.predict_proba(X_test_corr)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg0)\n",
        "pr_auc_lr0 = auc(recall_vals, precision_vals)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr0.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr0.best_score_)\n",
        "print(\"Test Score:\", pr_auc_lr0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3.loc['LogReg with 40 best features (selected by correlations with target)'] = [\n",
        "      round( grid_search_lr0.best_score_, 4),\n",
        "      round(pr_auc_lr0, 4),\n",
        "      10\n",
        "]\n",
        "\n",
        "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
        "\n",
        "display(df_metrics_part3.style\n",
        "    .background_gradient(subset=['auc_pr_test'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Качество почти такое же, как при отборе по весам**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E6yxKB2KBav"
      },
      "source": [
        "В качестве еще одной функция можно считать t-статистику:\n",
        "\n",
        "$$t(j) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
        "\n",
        "где $\\mu$, $\\sigma$, $n$ соответственно среднее, стандартное отклонение и количество объектов каждого из классов.\n",
        "\n",
        "Оставьте 40 признаков с наибольшим значением $t$, замерьте качество и скорость отбора признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xt = X_train_df.copy()\n",
        "Xt.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я решил написать **алгоритм отбора с аомощью t-stat в виде функции**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def selection_tstat(frame, target_col, n_best): \n",
        "\n",
        "    ft_tstat_list = []\n",
        "\n",
        "    frame_cl = frame.drop(columns=[target_col], axis=1)\n",
        "    for ft in frame_cl.columns.tolist():\n",
        "\n",
        "        m_plus = frame[frame[target_col]==1][ft].mean()\n",
        "        m_minus = frame[frame[target_col]==0][ft].mean()\n",
        "        \n",
        "        n_plus = frame[frame[target_col]==1].shape[0]\n",
        "        n_minus = frame[frame[target_col]==0].shape[0]\n",
        "        \n",
        "        sigma2_plus = frame[frame[target_col]==1][ft].var()\n",
        "        sigma2_minus = frame[frame[target_col]==0][ft].var()\n",
        "\n",
        "        t_stat_j = np.abs((m_plus - m_minus)) / np.sqrt((n_plus*sigma2_plus + n_minus*sigma2_minus) / (n_plus + n_minus)) # t-stat для j-го признака\n",
        "\n",
        "        ft_tstat_list.append({'feature': ft, 't_stat': t_stat_j})\n",
        "\n",
        "    ft_tstat_frame = pd.DataFrame(ft_tstat_list)\n",
        "\n",
        "    ft_tstat_frame = ft_tstat_frame.sort_values(by='t_stat', ascending=False)[:n_best] # вывожу n_best лучших\n",
        "\n",
        "\n",
        "    return ft_tstat_frame\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start10 = time.time()\n",
        "\n",
        "best_features_tstat = selection_tstat(Xt, 'target', 40)\n",
        "\n",
        "time10 = time.time() - start10\n",
        "\n",
        "print(f'Отбор признаков с помощью t-stat занял {round(time10, 3)} секунд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# обучаю модель на 40 лучших с точки зрения t-stat признаках\n",
        "\n",
        "top_40_tstat = best_features_tstat['feature']\n",
        "\n",
        "X_train_tstat = X_train_df.drop(columns='target', axis=1)\n",
        "X_test_tstat = X_test_df.copy()\n",
        "\n",
        "X_train_tstat = X_train_corr[top_40_tstat]\n",
        "X_test_tstat = X_test_corr[top_40_tstat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LogReg_top40tstat = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "grid_search_lr000 = GridSearchCV(LogReg_top40tstat, param_grid, cv = 5, verbose=2, scoring='average_precision') # 5 фолдов для кросс-валидации\n",
        "grid_search_lr000.fit(X_train_tstat, y_train)\n",
        "\n",
        "\n",
        "y_test_pred_logreg000 = grid_search_lr000.predict_proba(X_test_tstat)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg000)\n",
        "pr_auc_lr000 = auc(recall_vals, precision_vals)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr000.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr000.best_score_)\n",
        "print(\"Test Score:\", pr_auc_lr000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3.loc['LogReg with 40 best features (selected by t-stat)'] = [\n",
        "      round( grid_search_lr000.best_score_, 4),\n",
        "      round(pr_auc_lr000, 4),\n",
        "      10\n",
        "]\n",
        "\n",
        "display(df_metrics_part3.style\n",
        "    .background_gradient(subset=['auc_pr_test'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Пока не удается пробить качество выше auc_pr_test = 0.7674**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO63RNCLP75i"
      },
      "source": [
        "#### __Задание 11. Методы-обёртки__ (1 балл)\n",
        "\n",
        "Третий из рассматриваемых нами методов работает следующим образом: мы исключаем признаки по очереди и смотрим, как это влияет на качество. Удаляем признаки таким жадным способом, пока не окажется выполненым некоторое условие (количество признаков или ухудшение качества). Более конкретно, алгоритм выглядит так:\n",
        "\n",
        "- $k$ - число признаков, которых мы хотим оставить\n",
        "- $m$ - число признаков, которых мы выбрасываем на каждой итерации, оно же длина шага\n",
        "\n",
        "Шаг $i$:\n",
        "- $F_i$ - набор признаков (равный всему множеству признаков на i=0)\n",
        "- $M_i$ - их число, в общем случае $\\max(k, M_{i-1} - m)$\n",
        "1. Если признаков осталось ровно $k$, либо метрика стала уменьшаться более, чем на $\\epsilon$ — останавливаемся (не наш случай, но так тоже можно)\n",
        "2. Обучаем модель $a_i$ на наборе $F_i$, после чего оцениваем важность признаков (любым из способов выше или какими-нибудь ещё)\n",
        "3. Отбираем $\\min(M_i - k, m)$ наиболее бесполезных, согласно пункту 2, признаков (берем $m$, если можем, иначе оставляем вплоть до k), удаляем, переходим к следующему шагу\n",
        "\n",
        "Снова оставьте только 40 признаков и оцените качество на тестовой выборке. Подберите длину шага из каких-то соображений (каких, кстати?) и замерьте время работы метода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Мне понравился **метод с t-stat**, поэтому буду использовать его"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X11 = X_train_df.copy()\n",
        "X11.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_11 = X_test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def selection_tstat_11(frame, target_col): \n",
        "\n",
        "    ft_tstat_list = []\n",
        "\n",
        "    frame_cl = frame.drop(columns=[target_col], axis=1)\n",
        "    for ft in frame_cl.columns.tolist():\n",
        "\n",
        "        m_plus = frame[frame[target_col]==1][ft].mean()\n",
        "        m_minus = frame[frame[target_col]==0][ft].mean()\n",
        "        \n",
        "        n_plus = frame[frame[target_col]==1].shape[0]\n",
        "        n_minus = frame[frame[target_col]==0].shape[0]\n",
        "        \n",
        "        sigma2_plus = frame[frame[target_col]==1][ft].var()\n",
        "        sigma2_minus = frame[frame[target_col]==0][ft].var()\n",
        "\n",
        "        t_stat_j = np.abs((m_plus - m_minus)) / np.sqrt((n_plus*sigma2_plus + n_minus*sigma2_minus) / (n_plus + n_minus)) # t-stat для j-го признака\n",
        "\n",
        "        ft_tstat_list.append({'feature': ft, 't_stat': t_stat_j})\n",
        "\n",
        "    ft_tstat_frame = pd.DataFrame(ft_tstat_list)\n",
        "\n",
        "    ft_tstat_frame = ft_tstat_frame.sort_values(by='t_stat', ascending=False)                # возвращаю таблицу признаков по убыванию важности согласно t-stat\n",
        "\n",
        "\n",
        "    return ft_tstat_frame\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wrapper(frame_train):\n",
        "    k = frame_train.shape[1] - 1\n",
        "\n",
        "    pbar = tqdm(total=k-40)  # для отслеживания прогресса\n",
        "\n",
        "    frame_train_upd = frame_train.drop('target', axis=1)\n",
        "\n",
        "    current_features = frame_train_upd.columns.tolist()\n",
        "\n",
        "    while k > 40:\n",
        "\n",
        "        ft_tstat_frame_11 = selection_tstat_11(frame_train[current_features + ['target']], 'target')\n",
        "\n",
        "        features_step_i = ft_tstat_frame_11['feature'].tolist()[:-1]      # на каждом шаге выкидываю по 1 самому худшему признаку\n",
        "\n",
        "        current_features = features_step_i\n",
        "\n",
        "        k -= 1\n",
        "        pbar.update(1) \n",
        "\n",
        "    pbar.close()    \n",
        "\n",
        "    return features_step_i "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start11 = time.time()\n",
        "\n",
        "\n",
        "features_selected_by_wrapper = wrapper(X11)\n",
        "\n",
        "time11 = time.time() - start11\n",
        "print(f'Отбор признаков с помощью метода обертки занял {round(time11, 3)} секунд')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_selected_by_wrapper[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# обучаю модель на отобранных признаках и смотрю качество\n",
        "\n",
        "X11 = X11.drop(columns='target', axis=1)\n",
        "\n",
        "X_train_11 = X11[features_selected_by_wrapper]\n",
        "X_test_11 = X_test_11[features_selected_by_wrapper]\n",
        "\n",
        "\n",
        "\n",
        "LogReg_top40wrapper = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "grid_search_lr111 = GridSearchCV(LogReg_top40wrapper, param_grid, cv = 5, verbose=2, scoring='average_precision') # 5 фолдов для кросс-валидации\n",
        "grid_search_lr111.fit(X_train_11, y_train)\n",
        "\n",
        "\n",
        "y_test_pred_logreg111 = grid_search_lr111.predict_proba(X_test_11)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg111)\n",
        "pr_auc_lr111 = auc(recall_vals, precision_vals)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr111.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr111.best_score_)\n",
        "print(\"Test Score:\", pr_auc_lr111)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3.loc['LogReg with 40 best features (selected by wrapper)'] = [\n",
        "      round( grid_search_lr111.best_score_, 4),\n",
        "      round(pr_auc_lr111, 4),\n",
        "      10\n",
        "]\n",
        "\n",
        "display(df_metrics_part3.style\n",
        "    .background_gradient(subset=['auc_pr_test'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(set(top_40_tstat) & set(features_selected_by_wrapper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Получается, отбор с помощью t-stat и отбор с помощью t-stat несколькими итерациями дают **одинаковый набор признаков**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AEL4z61P75j"
      },
      "source": [
        "Стоит отметить, что с помощью такого метода можно пойти и в обратную сторону. Попробуйте _добавлять_ самые полезные признаки в выборку до тех пор, пока не наберется 40 штук. Найдется ли порог, при котором добавление следующих признаков будет только ухудшать качество модели?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X12 = X_train_df.copy()\n",
        "X_test_12 = X_test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# реализовываю алгоритм с добавлением признаков\n",
        "\n",
        "def wrapper_reversed(frame_train):\n",
        "    k = 1\n",
        "\n",
        "    pbar = tqdm(total=k-40)  # для отслеживания прогресса\n",
        "\n",
        "    frame_train_upd = frame_train.drop('target', axis=1)\n",
        "\n",
        "    current_features = frame_train_upd.columns.tolist()\n",
        "\n",
        "    ft_tstat_frame_11 = selection_tstat_11(frame_train[current_features + ['target']], 'target')\n",
        "\n",
        "    while k <= 40:\n",
        "\n",
        "        \n",
        "\n",
        "        features_step_j = ft_tstat_frame_11['feature'].tolist()[:k]      # на каждом шаге добавляю по 1 признаку\n",
        "\n",
        "        current_features = features_step_j\n",
        "\n",
        "        k += 1\n",
        "        pbar.update(1) \n",
        "\n",
        "    pbar.close()    \n",
        "\n",
        "    return features_step_j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start12 = time.time()\n",
        "\n",
        "\n",
        "features_selected_by_reversed_wrapper = wrapper_reversed(X12)\n",
        "\n",
        "time12 = time.time() - start12\n",
        "print(f'Отбор признаков с помощью обратного метода обертки занял {round(time12, 3)} секунд')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Намного быстрее!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# обучаю модель на отобранных признаках и смотрю качество\n",
        "\n",
        "X12 = X12.drop(columns='target', axis=1)\n",
        "\n",
        "X_train_12 = X12[features_selected_by_reversed_wrapper]\n",
        "X_test_12 = X_test_12[features_selected_by_reversed_wrapper]\n",
        "\n",
        "\n",
        "\n",
        "LogReg_top40wrapper_rev = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "grid_search_lr1112 = GridSearchCV(LogReg_top40wrapper_rev, param_grid, cv = 5, verbose=2, scoring='average_precision') # 5 фолдов для кросс-валидации\n",
        "grid_search_lr1112.fit(X_train_12, y_train)\n",
        "\n",
        "\n",
        "y_test_pred_logreg1112 = grid_search_lr1112.predict_proba(X_test_12)[:,1]\n",
        "\n",
        "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred_logreg1112)\n",
        "pr_auc_lr1112 = auc(recall_vals, precision_vals)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search_lr1112.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid_search_lr1112.best_score_)\n",
        "print(\"Test Score:\", pr_auc_lr1112)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics_part3.loc['LogReg with 40 best features (selected by reversed wrapper)'] = [\n",
        "      round( grid_search_lr1112.best_score_, 4),\n",
        "      round(pr_auc_lr1112, 4),\n",
        "      10\n",
        "]\n",
        "\n",
        "display(df_metrics_part3.style\n",
        "    .background_gradient(subset=['auc_pr_test'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ожидаемо, **качество такое же**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Построим **визуализацию динамики качества на тестовой выборке** с добавлением новых признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X13 = X_train_df.copy()\n",
        "X_test_13 = X_test_df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я строю модель без подбора гиперпараметров GridSearch, так как иначе **вычисления слишком долгие**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = 1\n",
        "arr_k = [k]\n",
        "\n",
        "ft_tstat_frame_11 = selection_tstat_11(X13, 'target')\n",
        "sorted_features = ft_tstat_frame_11['feature'].tolist()\n",
        "\n",
        "aucs = [0]\n",
        "X_test_13_full = X_test_13[sorted_features]\n",
        "\n",
        "total_iterations = X13.shape[1] - 1 - k\n",
        "pbar = tqdm(total=total_iterations)\n",
        "\n",
        "simple_logreg = LogisticRegression(penalty='l2', C=1.0, max_iter=1000)\n",
        "\n",
        "while k < X13.shape[1] - 1:\n",
        "    current_features = sorted_features[:k]\n",
        "    \n",
        "    X_train_13 = X13[current_features]\n",
        "    X_test_13 = X_test_13_full[current_features]\n",
        "    \n",
        "    simple_logreg.fit(X_train_13, y_train)\n",
        "    y_test_pred = simple_logreg.predict_proba(X_test_13)[:,1]\n",
        "    \n",
        "    precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_test_pred)\n",
        "    pr_auc_lr1112 = auc(recall_vals, precision_vals)\n",
        "    \n",
        "    k += 1\n",
        "    arr_k.append(k)\n",
        "    aucs.append(pr_auc_lr1112)\n",
        "    pbar.update(1)\n",
        "\n",
        "pbar.close()\n",
        "print('Готово')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(arr_k), len(aucs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Строю график:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(x=arr_k, \n",
        "              y=aucs,\n",
        "              title='Динамика качества при добавлении признаков',\n",
        "              color_discrete_sequence=[\"#7E1279\"])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Количество признаков',          \n",
        "    yaxis_title='PR-AUC',\n",
        "    title_font_size=20,     \n",
        "    font=dict(size=12)     \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# график можно посмотреть в Quality_dynamics.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Явного **ухудшения качества, начиная с какого-то порога, не наблюдается**.\\\n",
        "Просто, начиная с ~30 признаков **качество выходит на ассимптоту**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj6a-BERP75j"
      },
      "source": [
        "Давайте подведём итоги по отбору признаков. Назовите преимущества и недостатки каждого из методов. Какой метод привёл к наилучшему качеству?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(df_metrics_part3.style\n",
        "    .background_gradient(subset=['auc_pr_test'], cmap='RdYlGn'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Что касается качества, все методы, кроме отбора с помощью Random Forest, дали **практически идентичный результат** => есть ядро из 40 сильных признаков.\\\n",
        "Самым долгим с отрывом оказался отбор с помощью метода-обертки.\\\n",
        "Главный минус методов обертки - **вычислительная сложность и скорость выполнения**.\\\n",
        "Метод с отбором с помощью tstat хорош, но **требует нормальности распределения.**\\\n",
        "Метод с корреяциями также дал высокий результат, но он **не учитывает взаимодействия признаков.**\\\n",
        "Метод с весами модели тоже дал высокий результат, но в каких-то других случаях он может **упускать нелинейные закономерности**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Самое интересное, что **наилучшее качество у ЛогРега без отбора признаков**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrR06pp7P75k"
      },
      "source": [
        "# Часть 4. Оценка экономического эффекта модели (2 балла)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmgOdf7GT3uh"
      },
      "source": [
        "В данной части мы займемся тем, что от вас скорее всего потребуется на реальной работе (помимо перекладки `json`, разумеется). А именно:\n",
        "- мы соберем несколько специализированных метрик качества,\n",
        "- попытаемся настроить модель на максимизацию _прибыли_,\n",
        "- оценим, сколько вообще получится заработать на этом.\n",
        "\n",
        "Разумеется, здесь будет сделано множество упрощающих жизнь допущений, но обо всем по порядку. Если вы всё прослушали на экономике, то напомним, что выручка — это сколько денег нам принесли клиенты, а прибыль — выручка за вычетом расходов на зарплату и прочее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQkW5Xh6yip2"
      },
      "source": [
        "\n",
        "#### __Задание 12. Прогноз по доходам и расходам__ (1 балл)\n",
        "\n",
        "В этой части мы будем работать с данными [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Этот датасет содержит информацию о банковском телефонном маркетинге.\n",
        "\n",
        "__Объектом__ здесь является телефонный звонок потенциальному клиенту с предложением некоторой услуги (утверждается, что это краткосрочный депозит). В качестве признакового описания используются характеристики клиента (образование, брак и т.д.), данные о звонке и различные экономические индикаторы - более подробная информация представлена в файле `bank-additional-names.txt`.\n",
        "__Целевая переменная__ - ответ клиента (согласился ли он открыть депозит?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9WBqQd1aAjp"
      },
      "outputs": [],
      "source": [
        "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
        "#!unzip bank-additional.zip\n",
        "df = pd.read_csv('bank-additional-full.csv', sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Взял описание из интернета\n",
        "\n",
        "**Демографические признаки:**\n",
        "- `age` - возраст клиента в годах\n",
        "- `job` - тип профессии/рода занятий\n",
        "- `marital` - семейное положение\n",
        "- `education` - уровень образования\n",
        "- `default` - наличие кредита в дефолте\n",
        "- `housing` - наличие жилищного кредита\n",
        "- `loan` - наличие персонального кредита\n",
        "\n",
        "**Связанные с текущим контактом:**\n",
        "- `contact` - тип средства связи\n",
        "- `month` - последний месяц контакта в году\n",
        "- `day_of_week` - последний день недели контакта\n",
        "- `duration` - продолжительность последнего контакта в секундах\n",
        "\n",
        "**Прочие атрибуты:**\n",
        "- `campaign` - количество контактов во время этой кампании\n",
        "- `pdays` - количество дней с последнего контакта\n",
        "- `previous` - количество контактов до этой кампании\n",
        "- `poutcome` - результат предыдущей маркетинговой кампании\n",
        "\n",
        "**Экономические показатели:**\n",
        "- `emp.var.rate` - коэффициент вариации занятости\n",
        "- `cons.price.idx` - индекс потребительских цен\n",
        "- `cons.conf.idx` - индекс потребительского доверия\n",
        "- `euribor3m` - ставка Euribor за 3 месяца\n",
        "- `nr.employed` - количество сотрудников\n",
        "\n",
        "**Целевая переменная:**\n",
        "- `y` - подписал ли клиент срочный депозит (бинарный)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbw5k7lMaYT1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmxCn_Pz3kJB"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['duration', 'y'])\n",
        "y = (df.y == 'yes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMKgtxfwaBEQ"
      },
      "source": [
        "В этой части не нужно делить выборку - мы будем использовать кросс-валидацию.  Используйте наиболее подходящие с вашей точки зрения параметры и их значения (`shuffle`, `stratify`, число фолдов, ...). По кросс-валидации у вас получится несколько вариантов обучающей и тестовой выборки. Для удобства можно воспользоваться шаблоном ниже, который по ходу выполнения задания будет обрастать функционалом. Как обычно, это необязательно, но сохранять результаты экспериментов очень и очень желательно, в конце мы будем их сравнивать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# я добавил несколько возможных целевых метрик в этот шаблон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWH-ApMjY4et"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
        "\n",
        "def cross_validate(\n",
        "    X,\n",
        "    y,\n",
        "    model,\n",
        "    n_splits=5,\n",
        "    random_state=None,\n",
        "    shuffle=False,\n",
        "    scoring=None # целевая метрика\n",
        "    # другие аргументы, которые могут вам пригодиться дальше по пунктам\n",
        "):\n",
        "    metrics = []\n",
        "    # или любой другой фолд, посмотрите в model_selection\n",
        "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
        "\n",
        "    if scoring is None:\n",
        "        scoring = ['accuracy', 'precision', 'recall', 'f1', 'average_precision']\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "\n",
        "        # возьмите датасет и обучите модель\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Обучаем модель\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "        # для average_precision нужны вероятности\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            # Если модель не имеет predict_proba, используем decision_function\n",
        "            y_pred_proba = model.decision_function(X_test)\n",
        "        \n",
        "        # Предсказываем\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "\n",
        "        # посчитайте метрики, которые вам нужны и добавьте результаты с каждого фолда\n",
        "        metric_dict = {\n",
        "            # \"metric_key\": metric_value\n",
        "        }\n",
        "        if 'accuracy' in scoring:\n",
        "            metric_dict['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "        if 'precision' in scoring:\n",
        "            metric_dict['precision'] = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        if 'recall' in scoring:\n",
        "            metric_dict['recall'] = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        if 'f1' in scoring:\n",
        "            metric_dict['f1'] = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        if 'average_precision' in scoring:\n",
        "            metric_dict['average_precision'] = average_precision_score(y_test, y_pred_proba)    \n",
        "        \n",
        "        metrics.append(metric_dict)\n",
        "    \n",
        "    return pd.DataFrame(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIX-omTIyxtU"
      },
      "source": [
        "Выберите метрику классификации, которая вам кажется подходящей, и обучите логистическую регрессию на каждой обучающей выборке (закодируйте категориальные признаки способом, который выше вам понравился больше всех, отнормируйте числовые, гиперпараметры оставьте по умолчанию), сделайте предсказания для соответствующих тестовых выборок, выведите результаты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На лекции рассказывали, что для подобных задач хорошо подходит **lift** и похожие на него метрики.\\\n",
        "Поэтому я решил использовать **precision_at_k** - доля True Positives среди первых К элементов проранжированного по убыванию вероятности принадлежности к положительному классу ряда объектов.\\\n",
        "Также есть **Average Precision** - метрика, отражающая средний precision на позициях, где есть TP элементы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_value = 'admin.'\n",
        "\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':  # проверяем только текстовые столбцы\n",
        "        if target_value in X[col].values:\n",
        "            print(f\"Значение '{target_value}' найдено в столбце: {col}\")\n",
        "            print(f\"Все уникальные значения в '{col}': {X[col].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X.replace('admin.', 'administrator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['nr.employed'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# подготовка признаков\n",
        "\n",
        "categorical_features = ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']  # категориальные признаки\n",
        "numeric_features = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'] # числовые признаки\n",
        "\n",
        "preprocessor12 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "preprocessor12.fit(X)\n",
        "X_transformed = preprocessor12.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(random_state=777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_transformed_df = pd.DataFrame(X_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_ap = cross_validate(\n",
        "    X_transformed_df, y, model,\n",
        "    n_splits=5,\n",
        "    scoring=['average_precision']  # только интересующая нас метрика - average_precision\n",
        ")\n",
        "\n",
        "print(\"Average Precision по фолдам:\")\n",
        "print(results_ap)\n",
        "print(f\"\\nСредний Average Precision: {results_ap['average_precision'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Качество ужасное. Посмотрим на баланс классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Наблюдается **сильный дисбаланс классов**. Скорее всего, качество низкое из-за него. Попробую обучить лог регрессию с балансировкой классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "balanced_lr = LogisticRegression(\n",
        "    random_state=777,\n",
        "    class_weight='balanced',  # автоматическая балансировка\n",
        "    max_iter=1000,\n",
        "    C=1.0,\n",
        "    solver='liblinear'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_ap = cross_validate(\n",
        "    X_transformed_df, y, balanced_lr,\n",
        "    n_splits=5,\n",
        "    scoring=['average_precision']  # только интересующая нас метрика - average_precision\n",
        ")\n",
        "\n",
        "print(\"Average Precision по фолдам:\")\n",
        "print(results_ap)\n",
        "print(f\"\\nСредний Average Precision: {results_ap['average_precision'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Балансировка не помогла**.\\\n",
        "Попробуем прикинуть силу признаков, оценив корреляции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ корреляции признаков с целевой переменной\n",
        "\n",
        "y_numeric = y\n",
        "correlations = []\n",
        "for col in X.columns:\n",
        "    if X[col].dtype in ['int64', 'float64']:\n",
        "        corr = np.corrcoef(X[col], y_numeric)[0, 1]\n",
        "        correlations.append((col, corr, abs(corr)))\n",
        "\n",
        "correlations.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "print(\"Топ-10 признаков по корреляции:\")\n",
        "for col, corr, abs_corr in correlations[:10]:\n",
        "    print(f\"{col:20} | Корреляция: {corr:7.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Признаки **очень слабо коррелированы с таргетом** => такое плохое качество ожидаемо"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcuHfZjfzmnt"
      },
      "source": [
        "Допустим, работники вашего колл-центра получают за один звонок клиенту 2 доллара. При согласии клиента на предлагаемые условия он принесет в банк 10 долларов. Предположим, что всем положительным прогнозам ваши сотрудники решили позвонить.\n",
        "\n",
        "В качестве бизнес-метрики в нашей задаче мы будем считать прибыль aka `profit`, соответственно лучшую модель будем выбирать исходя из этого.\n",
        "Посчитайте на всех тестовых выборках выручку и сохраните результаты для бизнес-метрики вместе с предыдущей метрикой, которую вы выбрали\n",
        "\n",
        "Ответьте на вопросы:\n",
        "- Сколько денег вы в среднем заработаете?\n",
        "- Какое получилось стандартное отклонение профита?\n",
        "- Сколько из заработанных денег придётся отдать операторам вашего колл-центра?\n",
        "- Пропорциональна ли бизнес-метрика выбранной метрике классификации?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция для расчета прибыли\n",
        "def calculate_profit(y_true, y_pred_proba, threshold=0.5):\n",
        "\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    \n",
        "    n_calls = np.sum(y_pred)\n",
        "    \n",
        "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    \n",
        "    call_cost = -2 * n_calls  \n",
        "    revenue = 10 * true_positives  \n",
        "    profit = revenue + call_cost\n",
        "    \n",
        "    return profit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_costs(y_true, y_pred_proba, threshold=0.5):\n",
        "\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    \n",
        "    n_calls = np.sum(y_pred)\n",
        "    \n",
        "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    \n",
        "    call_cost = -2 * n_calls  \n",
        "    revenue = 10 * true_positives  \n",
        "    profit = revenue + call_cost\n",
        "    \n",
        "    return call_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для подсчета прибыли я изменил cross-validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_cross_validate(estimator, X, y, cv=5):\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import average_precision_score\n",
        "    \n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=777)\n",
        "    \n",
        "    ap_scores = []\n",
        "    profits = []\n",
        "    costs = []\n",
        "    \n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = clone(estimator)\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        \n",
        "        ap_score = average_precision_score(y_test, y_pred_proba)\n",
        "        ap_scores.append(ap_score)\n",
        "        \n",
        "        profit = calculate_profit(y_test.values, y_pred_proba, threshold=0.5)\n",
        "        profits.append(profit)\n",
        "\n",
        "        cost = calculate_costs(y_test.values, y_pred_proba, threshold=0.5)\n",
        "        costs.append(cost)\n",
        "    \n",
        "    return ap_scores, profits, costs\n",
        "\n",
        "ap_scores, profits, costs = simple_cross_validate(balanced_lr, X_transformed_df, y, cv=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_profits_costs = pd.DataFrame()\n",
        "scores_profits_costs['scores'] = ap_scores\n",
        "scores_profits_costs['profits'] = profits\n",
        "scores_profits_costs['costs'] = costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'В среднем мы заработаем {scores_profits_costs['profits'].mean()}$')\n",
        "\n",
        "print(f'Стандартное отклонение прибыли = {round(scores_profits_costs['profits'].std(), 4)}$')\n",
        "\n",
        "print(f'Отдать операторам придется  в среднем {np.abs(scores_profits_costs['costs'].mean())}$')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_ap['profit'] = scores_profits_costs['profits']\n",
        "results_ap['proportion'] = results_ap['profit'] / results_ap['average_precision']\n",
        "results_ap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Нельзя сказать, что метрики пропорциональны**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da1x6u6wP75k"
      },
      "source": [
        "Внесем некоторую долю случайности. Пусть теперь согласный на условия клиент будет приносить не 10 долларов, а случайную величину, равномерно распределенную в интервале $[0;20)$. Проделайте все те же самые действия. Для имитации реальной ситуации **НЕ** фиксируйте `random_seed` при подсчете выручки с клиента (для разбиения на фолды разумеется оставьте). Что получилось?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция для расчета прибыли\n",
        "def calculate_profit_random(y_true, y_pred_proba, threshold=0.5):\n",
        "\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    \n",
        "    n_calls = np.sum(y_pred)\n",
        "    \n",
        "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
        "\n",
        "\n",
        "    if true_positives > 0:\n",
        "        random_revenues = np.random.uniform(0, 20, true_positives)\n",
        "        total_revenue = np.sum(random_revenues)\n",
        "    else:\n",
        "        total_revenue = 0\n",
        "    \n",
        "    call_cost = -2 * n_calls   \n",
        "    profit = total_revenue + call_cost\n",
        "    \n",
        "    return profit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_cross_validate_random_profit(estimator, X, y, cv=5):\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import average_precision_score\n",
        "    \n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=777)\n",
        "    \n",
        "    ap_scores = []\n",
        "    profits = []\n",
        "    costs = []\n",
        "    \n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = clone(estimator)\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        \n",
        "        ap_score = average_precision_score(y_test, y_pred_proba)\n",
        "        ap_scores.append(ap_score)\n",
        "        \n",
        "        profit = calculate_profit_random(y_test.values, y_pred_proba, threshold=0.5)\n",
        "        profits.append(profit)\n",
        "\n",
        "        cost = calculate_costs(y_test.values, y_pred_proba, threshold=0.5)\n",
        "        costs.append(cost)\n",
        "    \n",
        "    return ap_scores, profits, costs\n",
        "\n",
        "ap_scores, profits, costs = simple_cross_validate_random_profit(balanced_lr, X_transformed_df, y, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_profits_costs = pd.DataFrame()\n",
        "scores_profits_costs['scores'] = ap_scores\n",
        "scores_profits_costs['profits'] = profits\n",
        "scores_profits_costs['costs'] = costs\n",
        "\n",
        "scores_profits_costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_ap['profit2'] = scores_profits_costs['profits']\n",
        "results_ap['proportion2'] = results_ap['profit2'] / results_ap['average_precision']\n",
        "results_ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Средняя прибыль при равномерно распределенном выигрыше = {round(results_ap['profit2'].mean(), 3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Результаты схожи**, средняя прибыли при случайном выигрыше чуть выше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1g9FPExP75k"
      },
      "source": [
        "Настройте по кросс-валидации коэффициент регуляризации модели для максимизации прибыли (считайте как случайную величину выше). Удалось ли получить какой-то выигрыш? При каком коэффициенте регуляризациии прибыль максимальна? Постройте график зависимости ожидаемой прибыли от коэффициента"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_cross_val_profit(estimator, X, y, C_values, cv=5):\n",
        "\n",
        "    \n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=777)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for C in tqdm(C_values):\n",
        "        profits_fold = []\n",
        "        \n",
        "        for train_idx, test_idx in kf.split(X):\n",
        "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "            \n",
        "            # Создаем модель с конкретным C\n",
        "            model = clone(estimator)\n",
        "            model.set_params(C=C)  \n",
        "            \n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            \n",
        "            profit = calculate_profit_random(y_test.values, y_pred_proba, threshold=0.5)\n",
        "            profits_fold.append(profit)\n",
        "        \n",
        "        results[C] = {\n",
        "            'mean_profit': np.mean(profits_fold),\n",
        "            'all_profits': profits_fold\n",
        "        }\n",
        "    \n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
        "results = simple_cross_val_profit(balanced_lr, X_transformed_df, y, C_values, cv=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame(results)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "maxprofit = results.max(axis=1)['mean_profit']\n",
        "c_maxprofit = results.idxmax(axis=1)['mean_profit']\n",
        "print(f'Прибыль максимальна при коэффициенте регуляризации = {c_maxprofit}  и равна {round(results.max(axis=1)['mean_profit'], 3)} $')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Прибыль выше на ~50$**, выигрыш есть, но он не очень большой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### График зависимости ожидаемой прибыли от коэффициента регуляризации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c_reg = np.array(results.columns)\n",
        "mean_profits = np.array(results.iloc[0].values)\n",
        "\n",
        "\n",
        "\n",
        "fig = px.line(x=c_reg, \n",
        "              y=mean_profits, \n",
        "              title='Зависимость ожидаемой прибыли от коэффициента регуляризации',\n",
        "              color_discrete_sequence=[\"#098117\"])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Коэффициент регуляризации',          \n",
        "    yaxis_title='Ожидаемая прибыль',\n",
        "    title_font_size=20,     \n",
        "    font=dict(size=12)     \n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    line_width=2       \n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# график можно посмотреть в Profit_dynamics_by_reg_coef.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для наглядности построю такой же график без учета больших C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c_reg = np.array(results.columns)\n",
        "mean_profits = np.array(results.iloc[0].values)\n",
        "\n",
        "\n",
        "\n",
        "fig = px.line(x=c_reg[:-3], \n",
        "              y=mean_profits[:-3], \n",
        "              title='Зависимость ожидаемой прибыли от коэффициента регуляризации',\n",
        "              color_discrete_sequence=[\"#098117\"])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Коэффициент регуляризации',          \n",
        "    yaxis_title='Ожидаемая прибыль',\n",
        "    title_font_size=20,     \n",
        "    font=dict(size=12)     \n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    line_width=2       \n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdptRdaIP75l"
      },
      "source": [
        "Попробуйте запустить перебор несколько раз. Находится ли каждый раз один и тот же \"лучший\" коэффициент? Присутствует ли какая-то закономерность? Какие вы можете сделать из этого выводы?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_cross_val_profit_several_times(estimator, X, y, C_values, cv=5):\n",
        "\n",
        "    \n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=777)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for C in tqdm(C_values):\n",
        "        profits_fold = []\n",
        "        \n",
        "        for train_idx, test_idx in kf.split(X):\n",
        "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "            \n",
        "            # Создаем модель с конкретным C\n",
        "            model = clone(estimator)\n",
        "            model.set_params(C=C)  \n",
        "            \n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            \n",
        "            profit = calculate_profit_random(y_test.values, y_pred_proba, threshold=0.5)\n",
        "            profits_fold.append(profit)\n",
        "        \n",
        "        results[C] = {\n",
        "            'mean_profit': np.mean(profits_fold),\n",
        "            'all_profits': profits_fold\n",
        "        }\n",
        "        results = pd.DataFrame(results)\n",
        "    \n",
        "    return results.idxmax(axis=1)['mean_profit']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# запускаю функцию 10 раз\n",
        "\n",
        "[simple_cross_val_profit_several_times(balanced_lr, X_transformed_df, y, C_values, cv=5) for _ in range(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вывод**: в большинстве случаев C большой => **сильная регуляризация не нужна**\\\n",
        "Я думаю можно использовать C=10000 или 1000, скорее всего разница будет небольшая"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0j8HubaP75l"
      },
      "source": [
        "#### __Задание 13. Ключевая метрика__ (1 балл)\n",
        "\n",
        "Выше мы уже описали примерную экономическую модель вашей задачи. Как вы считаете, что для вашего бизнеса важнее — хороший precision или recall модели? Почему?\n",
        "\n",
        "__Ответ:__ recall здесь важнее, так как **высокий recall => меньше пропускаем готовых заключить депозит клиентов**\\\n",
        "Издержки на звонок меньше ожидаемой прибыли от заключения депозита, поэтому precision не так важен\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LFRNnrtP75m"
      },
      "source": [
        "> Вспомним, что на самом деле логистическая регрессия предсказывает нам вероятности положительного класса для объекта. Возможно, путем настройки __порога бинаризации__ этих вероятностей мы сможем получить какой-то выигрыш?\n",
        "\n",
        "Проверьте ваши рассуждения выше с помощью настройки порога бинаризации на кросс-валидации для максимизации прибыли. Воспользуйтесь сеткой от 0 до 1 с шагом 0.01. Напомним, что снижение порога дает нам более высокий recall и более низкий precision, и наоборот. Добавьте новую ML-метрику в ваш CV-пайплайн, найдите такой порог, при котором бизнес-метрика максимальна, и проверьте, связана ли новая ML метрика с профитом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_cross_val_profit_threshold(estimator, X, y, thresholds, C, cv=5):\n",
        "\n",
        "    \n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=777)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for threshold in tqdm(thresholds):\n",
        "        profits_fold = []\n",
        "        recalls_fold = [] \n",
        "        \n",
        "        for train_idx, test_idx in kf.split(X):\n",
        "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "            \n",
        "            # Создаем модель с конкретным C\n",
        "            model = clone(estimator)\n",
        "            model.set_params(C=C)  \n",
        "            \n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "            \n",
        "            profit = calculate_profit_random(y_test.values, y_pred_proba, threshold=threshold)\n",
        "            profits_fold.append(profit)\n",
        "\n",
        "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "            recalls_fold.append(recall_score(y_test, y_pred))\n",
        "        \n",
        "        results[threshold] = {\n",
        "            'mean_profit': np.mean(profits_fold),\n",
        "            'profis_by_folds': profits_fold,\n",
        "            'mean_recalls': np.mean(recalls_fold) \n",
        "        }\n",
        "        results = pd.DataFrame(results)\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thresholds = np.arange(0, 1.01, 0.01)\n",
        "results = simple_cross_val_profit_threshold(balanced_lr, X_transformed_df, y, thresholds, C = 10000, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "maxprofit = results.max(axis=1)['mean_profit']\n",
        "t_maxprofit = results.idxmax(axis=1)['mean_profit']\n",
        "recall_maxprofit = results[t_maxprofit]['mean_recalls']\n",
        "print(f'Прибыль максимальна при пороге бинаризации = {t_maxprofit}  и равна {round(maxprofit, 3)} $. Recall в таком случае = {round(recall_maxprofit, 3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Recall достаточно низкий при максимальной прибыли**. Построим графики зависимости Recall и прибыли от порога бинаризации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trs = np.array(results.columns)\n",
        "profits = results.iloc[0].values\n",
        "recalls = results.iloc[2].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Постройте график зависимости прибыли от порога бинаризации. Выделите наилучший порог"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(x=trs, \n",
        "              y=profits, \n",
        "              title='Зависимость ожидаемой прибыли от порога бинаризации',\n",
        "              color_discrete_sequence=[\"#7E1279\"])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Порог бинаризации',          \n",
        "    yaxis_title='Ожидаемая прибыль',\n",
        "    title_font_size=20,     \n",
        "    font=dict(size=12)     \n",
        ")\n",
        "\n",
        "fig.add_scatter(\n",
        "    x=[results.idxmax(axis=1)['mean_profit']], \n",
        "    y=[results.max(axis=1)['mean_profit']],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        color='red',\n",
        "        size=12,\n",
        "        symbol='star',  # Звезда вместо круга\n",
        "        line=dict(color='darkred', width=2)\n",
        "    ),\n",
        "    name=f'Максимум: {results.max(axis=1)['mean_profit']:.2f} \\\n",
        "           Порог = {results.idxmax(axis=1)['mean_profit']}'\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Порог бинаризации',          \n",
        "    yaxis_title='Ожидаемая прибыль',\n",
        "    title_font_size=20,     \n",
        "    font=dict(size=12)     \n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    line_width=2       \n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# график можно посмотреть в Profit_dynamics_by_binarization_threshold.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(x=trs, \n",
        "              y=recalls, \n",
        "              title='Зависимость Recall от порога бинаризации',\n",
        "              color_discrete_sequence=[\"#5F1268\"])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Порог бинаризации',          \n",
        "    yaxis_title='Recall',\n",
        "    title_font_size=20,     \n",
        "    font=dict(size=12)     \n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    line_width=2       \n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# график можно посмотреть в Recall_dynamics_by_binarization_threshold.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjw2DImXXoFx"
      },
      "source": [
        "__Вопрос:__ Замечаете ли вы какую-то закономерность? Для правильного ответа на этот вопрос попробуйте запустить несколько раз и задумайтесь, почему порог получается в какой-то конкретной области?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfnHUQ7sXouL"
      },
      "source": [
        "__Ответ:__ Да, **оптимальный порог всегда в районе 0.6 - 0.7**\\\n",
        "Это говорит о том, что с точки зрения максимизации прибыли, **лучше пропустить несколько клиентов, чем звонить всем подряд**\\\n",
        "Порог 0.6 - 0.7 дает оптимальный **баланс между precision и recall**\\\n",
        "При низком пороге Recall высокий, но слишком много ложных срабатываний => **огромные издержки**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tyapxyGdrSX"
      },
      "source": [
        "Наконец, чтобы точнее понять, что наша модель лучше исходной, посчитайте среднее и стандартное отклонение по фолдам бизнес-метрики для оптимизированной модели (гиперпараметры + порог) и дефолтной логистической регрессии. Проверьте, действительно ли удалось добиться значимого изменения прибыли — примените какой-либо статистический тест (например, парный t-критерий с $\\alpha=0.95$) к метрике, полученной двумя этими моделями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# обучаю дефолтный логрег\n",
        "\n",
        "def simple_cross_val_profit_default_df(estimator, X, y, cv=5):\n",
        "    \n",
        "    kf = KFold(n_splits=cv, shuffle=True, random_state=777)\n",
        "    \n",
        "    profits_fold = []\n",
        "    recalls_fold = []\n",
        "    \n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        \n",
        "        model = clone(estimator)\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "        profit = calculate_profit_random(y_test.values, y_pred_proba, threshold=0.5)\n",
        "        profits_fold.append(profit)\n",
        "\n",
        "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "        recalls_fold.append(recall_score(y_test, y_pred))\n",
        "    \n",
        "    results_def = pd.DataFrame({\n",
        "        'mean_profit': [np.mean(profits_fold)],\n",
        "        'profits_by_folds': [profits_fold],\n",
        "        'mean_recall': [np.mean(recalls_fold)],\n",
        "    })\n",
        "    \n",
        "    return results_def\n",
        "\n",
        "results_default = simple_cross_val_profit_default_df(balanced_lr, X_transformed_df, y, cv=5)\n",
        "results_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kosI-CEjeeSb"
      },
      "outputs": [],
      "source": [
        "# Оптимизированная лог регрессия\n",
        "results[t_maxprofit]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Ожидаемая прибыль для оптимизированной модели = {np.array(results[t_maxprofit]['profis_by_folds']).mean():.2f}, стандартное отклонение прибыли = {np.array(results[t_maxprofit]['profis_by_folds']).std():.2f}')\n",
        "\n",
        "print(f'Ожидаемая прибыль для дефолтной модели = {np.array(results_default.iloc[0]['profits_by_folds']).mean():.2f}, стандартное отклонение прибыли = {np.array(results_default.iloc[0]['profits_by_folds']).std():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Средние сильно различаются, посмотрим, статистически значима ли эта разница**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "У нас парные наблюдения и маленькая выборка => подходит **ttest_rel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "profit_model_default = np.array(results_default.iloc[0]['profits_by_folds'])\n",
        "profit_model_ortimized = np.array(results[t_maxprofit]['profis_by_folds'])\n",
        "\n",
        "t_stat, p_value = ttest_rel(profit_model_ortimized, profit_model_default, alternative='greater') # проверяю гипотезу что ожидаемая прибыль оптимальной модели выше чем дефолтной\n",
        "\n",
        "print(f\"t-статистика: {t_stat:.3f}\")\n",
        "print(f\"p-value: {p_value:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_value < 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "p-value < уровня значимости => нулевая гипотеза отвергается => **Оптимизированная модель значимо лучше**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xvhLtt4OP75Q",
        "RvWzOe4wP75T",
        "4VbJR0e3P75U"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
